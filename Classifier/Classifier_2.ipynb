{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import models as m\n",
    "from tensorflow.python.keras import layers as l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.18/04\n",
      "All classes initialized succesfully.\n"
     ]
    }
   ],
   "source": [
    "from ROOT import TFile, TTree, TChain\n",
    "print(\"All classes initialized succesfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from the trees. Printing out the contents.\n"
     ]
    }
   ],
   "source": [
    "sigChan = TChain(\"varTree\")\n",
    "sigChan.Add(\"signal.root\")\n",
    "bkgChan = TChain(\"varTree\")\n",
    "bkgChan.Add(\"background.root\")\n",
    "print(\"Data read from the trees. Printing out the contents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************\n",
      "*Chain   :varTree   : signal.root                                            *\n",
      "******************************************************************************\n",
      "******************************************************************************\n",
      "*Tree    :varTree   : Input Variables List for Algorithms                    *\n",
      "*Entries :    44440 : Total =         3213746 bytes  File  Size =    2732257 *\n",
      "*        :          : Tree compression factor =   1.17                       *\n",
      "******************************************************************************\n",
      "*Br    0 :HtJet     : HtJet/D                                                *\n",
      "*Entries :    44440 : Total  Size=     356973 bytes  File Size  =      24645 *\n",
      "*Baskets :       12 : Basket Size=      32000 bytes  Compression=  14.46     *\n",
      "*............................................................................*\n",
      "*Br    1 :dRLL      : dRLL/D                                                 *\n",
      "*Entries :    44440 : Total  Size=     356957 bytes  File Size  =     333416 *\n",
      "*Baskets :       12 : Basket Size=      32000 bytes  Compression=   1.07     *\n",
      "*............................................................................*\n",
      "*Br    2 :dPhiLepMETSelObj : dPhiLepMETSelObj/D                              *\n",
      "*Entries :    44440 : Total  Size=     357149 bytes  File Size  =     338144 *\n",
      "*Baskets :       12 : Basket Size=      32000 bytes  Compression=   1.05     *\n",
      "*............................................................................*\n",
      "*Br    3 :YDelpObj  : YDelpObj/D                                             *\n",
      "*Entries :    44440 : Total  Size=     357021 bytes  File Size  =     341350 *\n",
      "*Baskets :       12 : Basket Size=      32000 bytes  Compression=   1.04     *\n",
      "*............................................................................*\n",
      "*Br    4 :YUserObj  : YUserObj/D                                             *\n",
      "*Entries :    44440 : Total  Size=     357021 bytes  File Size  =     342208 *\n",
      "*Baskets :       12 : Basket Size=      32000 bytes  Compression=   1.04     *\n",
      "*............................................................................*\n",
      "*Br    5 :alphaT    : alphaT/D                                               *\n",
      "*Entries :    44440 : Total  Size=     356989 bytes  File Size  =     334194 *\n",
      "*Baskets :       12 : Basket Size=      32000 bytes  Compression=   1.07     *\n",
      "*............................................................................*\n",
      "*Br    6 :Sphericity : Sphericity/D                                          *\n",
      "*Entries :    44440 : Total  Size=     357053 bytes  File Size  =     338633 *\n",
      "*Baskets :       12 : Basket Size=      32000 bytes  Compression=   1.05     *\n",
      "*............................................................................*\n",
      "*Br    7 :Spherocity : Spherocity/D                                          *\n",
      "*Entries :    44440 : Total  Size=     357053 bytes  File Size  =     339191 *\n",
      "*Baskets :       12 : Basket Size=      32000 bytes  Compression=   1.05     *\n",
      "*............................................................................*\n",
      "*Br    8 :MtLeadLepMET : MtLeadLepMET/D                                      *\n",
      "*Entries :    44440 : Total  Size=     357085 bytes  File Size  =     338631 *\n",
      "*Baskets :       12 : Basket Size=      32000 bytes  Compression=   1.05     *\n",
      "*............................................................................*\n",
      "******************************************************************************\n",
      "*Chain   :varTree   : background.root                                        *\n",
      "******************************************************************************\n",
      "******************************************************************************\n",
      "*Tree    :varTree   : Input Variables List for Algorithms                    *\n",
      "*Entries :     4108 : Total =          302212 bytes  File  Size =     255633 *\n",
      "*        :          : Tree compression factor =   1.17                       *\n",
      "******************************************************************************\n",
      "*Br    0 :HtJet     : HtJet/D                                                *\n",
      "*Entries :     4108 : Total  Size=      33507 bytes  File Size  =       2197 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=  15.03     *\n",
      "*............................................................................*\n",
      "*Br    1 :dRLL      : dRLL/D                                                 *\n",
      "*Entries :     4108 : Total  Size=      33501 bytes  File Size  =      31470 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.05     *\n",
      "*............................................................................*\n",
      "*Br    2 :dPhiLepMETSelObj : dPhiLepMETSelObj/D                              *\n",
      "*Entries :     4108 : Total  Size=      33573 bytes  File Size  =      31386 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.05     *\n",
      "*............................................................................*\n",
      "*Br    3 :YDelpObj  : YDelpObj/D                                             *\n",
      "*Entries :     4108 : Total  Size=      33525 bytes  File Size  =      31701 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.04     *\n",
      "*............................................................................*\n",
      "*Br    4 :YUserObj  : YUserObj/D                                             *\n",
      "*Entries :     4108 : Total  Size=      33525 bytes  File Size  =      31759 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.04     *\n",
      "*............................................................................*\n",
      "*Br    5 :alphaT    : alphaT/D                                               *\n",
      "*Entries :     4108 : Total  Size=      33513 bytes  File Size  =      31483 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.05     *\n",
      "*............................................................................*\n",
      "*Br    6 :Sphericity : Sphericity/D                                          *\n",
      "*Entries :     4108 : Total  Size=      33537 bytes  File Size  =      31444 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.05     *\n",
      "*............................................................................*\n",
      "*Br    7 :Spherocity : Spherocity/D                                          *\n",
      "*Entries :     4108 : Total  Size=      33537 bytes  File Size  =      31537 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.05     *\n",
      "*............................................................................*\n",
      "*Br    8 :MtLeadLepMET : MtLeadLepMET/D                                      *\n",
      "*Entries :     4108 : Total  Size=      33549 bytes  File Size  =      31512 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.05     *\n",
      "*............................................................................*\n"
     ]
    }
   ],
   "source": [
    "sigChan.Print()\n",
    "bkgChan.Print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44440\n",
      "4108\n"
     ]
    }
   ],
   "source": [
    "# Read input data from root files\n",
    "sigSampleSize = sigChan.GetEntries()\n",
    "bkgSampleSize = bkgChan.GetEntries()\n",
    "print(sigSampleSize)\n",
    "print(bkgSampleSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          2.49833166  0.80792055  3.60755951  4.04035573  0.48130491\n",
      "  0.32805805  0.29058502 70.49661585]\n",
      "(44440, 9)\n",
      "(4108, 9)\n"
     ]
    }
   ],
   "source": [
    "# Convert the input data to matrices\n",
    "sigFull = sigChan.AsMatrix()\n",
    "bkgFull = bkgChan.AsMatrix()\n",
    "print(sigFull[0])\n",
    "print(sigFull.shape)\n",
    "print(bkgFull.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35552, 9)\n",
      "(3286, 9)\n",
      "(8888, 9)\n",
      "(822, 9)\n"
     ]
    }
   ],
   "source": [
    "# Choose 20% of the data for testing and 80% of the data for training\n",
    "sigTrain = sigFull[0:int(0.8*sigFull.shape[0])][:]\n",
    "bkgTrain = bkgFull[0:int(0.8*bkgFull.shape[0])][:]\n",
    "sigTest = sigFull[int(0.8*sigFull.shape[0]):][:]\n",
    "bkgTest = bkgFull[int(0.8*bkgFull.shape[0]):][:]\n",
    "print(sigTrain.shape)\n",
    "print(bkgTrain.shape)\n",
    "print(sigTest.shape)\n",
    "print(bkgTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[ 3.26113929  2.85206341  0.71608697  7.10178975  2.41076365  1.64264783\n",
      "  0.2280836   0.07920158 57.8950444 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scaler.save']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a scaler for input features\n",
    "scaler = StandardScaler()\n",
    "scaler_input = np.concatenate((sigTrain,bkgTrain))\n",
    "print(scaler.fit(scaler_input))\n",
    "print(scaler.mean_)\n",
    "joblib.dump(scaler, \"scaler.save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model building complete!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-26 21:08:43.380598: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "per = m.Sequential()\n",
    "per.add(l.Dense(18, input_dim=sigTrain.shape[1], activation='relu'))\n",
    "per.add(l.Dropout(rate=0.2))\n",
    "per.add(l.Dense(18, activation='relu'))\n",
    "per.add(l.Dropout(rate=0.2))\n",
    "per.add(l.Dense(2, activation='softmax'))\n",
    "print(\"Model building complete!!!\")\n",
    "\n",
    "per.compile(optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3286\n",
      "822\n"
     ]
    }
   ],
   "source": [
    "# Loop to change the training sample every time\n",
    "# by randomly choosing from the avalaible sample space.\n",
    "# Make sure to run atleast so that each and every event has been used once.\n",
    "\n",
    "nShuffleRun = 10\n",
    "trainingSampleSize = sigTrain.shape[0] if sigTrain.shape[0]<bkgTrain.shape[0] else bkgTrain.shape[0]\n",
    "testSampleSize = sigTest.shape[0] if sigTest.shape[0]<bkgTest.shape[0] else bkgTest.shape[0]\n",
    "\n",
    "print(trainingSampleSize)\n",
    "print(testSampleSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Space:  (6572, 9)\n",
      "Train on 6572 samples, validate on 1644 samples\n",
      "Epoch 1/100\n",
      "6572/6572 [==============================] - 1s 119us/sample - loss: 0.9523 - accuracy: 0.4629 - val_loss: 1.0367 - val_accuracy: 0.4300\n",
      "Epoch 2/100\n",
      "6572/6572 [==============================] - 0s 8us/sample - loss: 0.8104 - accuracy: 0.5038 - val_loss: 0.8471 - val_accuracy: 0.5432\n",
      "Epoch 3/100\n",
      "6572/6572 [==============================] - 0s 8us/sample - loss: 0.7335 - accuracy: 0.5332 - val_loss: 0.7257 - val_accuracy: 0.5845\n",
      "Epoch 4/100\n",
      "6572/6572 [==============================] - 0s 8us/sample - loss: 0.6957 - accuracy: 0.5670 - val_loss: 0.6320 - val_accuracy: 0.6332\n",
      "Epoch 5/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.6498 - accuracy: 0.5948 - val_loss: 0.5952 - val_accuracy: 0.6575\n",
      "Epoch 6/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.6267 - accuracy: 0.6121 - val_loss: 0.5736 - val_accuracy: 0.6831\n",
      "Epoch 7/100\n",
      "6572/6572 [==============================] - 0s 14us/sample - loss: 0.6044 - accuracy: 0.6484 - val_loss: 0.5564 - val_accuracy: 0.7062\n",
      "Epoch 8/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.5964 - accuracy: 0.6663 - val_loss: 0.5430 - val_accuracy: 0.7263\n",
      "Epoch 9/100\n",
      "6572/6572 [==============================] - 0s 14us/sample - loss: 0.5781 - accuracy: 0.6656 - val_loss: 0.5347 - val_accuracy: 0.7226\n",
      "Epoch 10/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.5678 - accuracy: 0.6817 - val_loss: 0.5267 - val_accuracy: 0.7293\n",
      "Epoch 11/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.5547 - accuracy: 0.6894 - val_loss: 0.5200 - val_accuracy: 0.7269\n",
      "Epoch 12/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.5433 - accuracy: 0.6974 - val_loss: 0.5106 - val_accuracy: 0.7342\n",
      "Epoch 13/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.5396 - accuracy: 0.7104 - val_loss: 0.5017 - val_accuracy: 0.7476\n",
      "Epoch 14/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.5259 - accuracy: 0.7103 - val_loss: 0.4913 - val_accuracy: 0.7640\n",
      "Epoch 15/100\n",
      "6572/6572 [==============================] - 0s 14us/sample - loss: 0.5203 - accuracy: 0.7206 - val_loss: 0.4845 - val_accuracy: 0.7622\n",
      "Epoch 16/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.5238 - accuracy: 0.7171 - val_loss: 0.4773 - val_accuracy: 0.7628\n",
      "Epoch 17/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.5066 - accuracy: 0.7330 - val_loss: 0.4703 - val_accuracy: 0.7622\n",
      "Epoch 18/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.4995 - accuracy: 0.7339 - val_loss: 0.4623 - val_accuracy: 0.7682\n",
      "Epoch 19/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.4964 - accuracy: 0.7354 - val_loss: 0.4560 - val_accuracy: 0.7713\n",
      "Epoch 20/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.4909 - accuracy: 0.7427 - val_loss: 0.4500 - val_accuracy: 0.7719\n",
      "Epoch 21/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.4824 - accuracy: 0.7424 - val_loss: 0.4433 - val_accuracy: 0.7798\n",
      "Epoch 22/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.4725 - accuracy: 0.7505 - val_loss: 0.4377 - val_accuracy: 0.7822\n",
      "Epoch 23/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.4774 - accuracy: 0.7532 - val_loss: 0.4324 - val_accuracy: 0.7920\n",
      "Epoch 24/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.4617 - accuracy: 0.7600 - val_loss: 0.4261 - val_accuracy: 0.8017\n",
      "Epoch 25/100\n",
      "6572/6572 [==============================] - 0s 15us/sample - loss: 0.4627 - accuracy: 0.7575 - val_loss: 0.4226 - val_accuracy: 0.8047\n",
      "Epoch 26/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.4606 - accuracy: 0.7623 - val_loss: 0.4223 - val_accuracy: 0.7968\n",
      "Epoch 27/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.4558 - accuracy: 0.7695 - val_loss: 0.4272 - val_accuracy: 0.7877\n",
      "Epoch 28/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.4579 - accuracy: 0.7704 - val_loss: 0.4261 - val_accuracy: 0.7908\n",
      "Epoch 29/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.4511 - accuracy: 0.7730 - val_loss: 0.4237 - val_accuracy: 0.7871\n",
      "Epoch 30/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.4457 - accuracy: 0.7698 - val_loss: 0.4210 - val_accuracy: 0.7865\n",
      "Epoch 31/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.4485 - accuracy: 0.7715 - val_loss: 0.4166 - val_accuracy: 0.7932\n",
      "Epoch 32/100\n",
      "6572/6572 [==============================] - 0s 16us/sample - loss: 0.4420 - accuracy: 0.7771 - val_loss: 0.4102 - val_accuracy: 0.8035\n",
      "Epoch 33/100\n",
      "6572/6572 [==============================] - 0s 17us/sample - loss: 0.4380 - accuracy: 0.7824 - val_loss: 0.4064 - val_accuracy: 0.8120\n",
      "Epoch 34/100\n",
      "6572/6572 [==============================] - 0s 16us/sample - loss: 0.4355 - accuracy: 0.7886 - val_loss: 0.4073 - val_accuracy: 0.8072\n",
      "Epoch 35/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.4347 - accuracy: 0.7810 - val_loss: 0.4079 - val_accuracy: 0.8011\n",
      "Epoch 36/100\n",
      "6572/6572 [==============================] - 0s 14us/sample - loss: 0.4355 - accuracy: 0.7874 - val_loss: 0.4068 - val_accuracy: 0.8029\n",
      "Epoch 37/100\n",
      "6572/6572 [==============================] - 0s 14us/sample - loss: 0.4382 - accuracy: 0.7806 - val_loss: 0.4025 - val_accuracy: 0.8084\n",
      "Epoch 38/100\n",
      "6572/6572 [==============================] - 0s 14us/sample - loss: 0.4335 - accuracy: 0.7870 - val_loss: 0.3996 - val_accuracy: 0.8127\n",
      "Epoch 39/100\n",
      "6572/6572 [==============================] - 0s 14us/sample - loss: 0.4335 - accuracy: 0.7876 - val_loss: 0.3980 - val_accuracy: 0.8096\n",
      "Epoch 40/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.3961 - val_accuracy: 0.8102\n",
      "Epoch 41/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.4253 - accuracy: 0.7880 - val_loss: 0.3968 - val_accuracy: 0.8096\n",
      "Epoch 42/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.4278 - accuracy: 0.7888 - val_loss: 0.3952 - val_accuracy: 0.8090\n",
      "Epoch 43/100\n",
      "6572/6572 [==============================] - 0s 18us/sample - loss: 0.4239 - accuracy: 0.7902 - val_loss: 0.3951 - val_accuracy: 0.8096\n",
      "Epoch 44/100\n",
      "6572/6572 [==============================] - 0s 20us/sample - loss: 0.4167 - accuracy: 0.7999 - val_loss: 0.3925 - val_accuracy: 0.8133\n",
      "Epoch 45/100\n",
      "6572/6572 [==============================] - 0s 19us/sample - loss: 0.4221 - accuracy: 0.7932 - val_loss: 0.3914 - val_accuracy: 0.8212\n",
      "Epoch 46/100\n",
      "6572/6572 [==============================] - 0s 20us/sample - loss: 0.4173 - accuracy: 0.7915 - val_loss: 0.3911 - val_accuracy: 0.8175\n",
      "Epoch 47/100\n",
      "6572/6572 [==============================] - 0s 19us/sample - loss: 0.4201 - accuracy: 0.7871 - val_loss: 0.3913 - val_accuracy: 0.8212\n",
      "Epoch 48/100\n",
      "6572/6572 [==============================] - 0s 17us/sample - loss: 0.4121 - accuracy: 0.7987 - val_loss: 0.3911 - val_accuracy: 0.8187\n",
      "Epoch 49/100\n",
      "6572/6572 [==============================] - 0s 16us/sample - loss: 0.4106 - accuracy: 0.8046 - val_loss: 0.3895 - val_accuracy: 0.8181\n",
      "Epoch 50/100\n",
      "6572/6572 [==============================] - 0s 18us/sample - loss: 0.4129 - accuracy: 0.7963 - val_loss: 0.3879 - val_accuracy: 0.8230\n",
      "Epoch 51/100\n",
      "6572/6572 [==============================] - 0s 18us/sample - loss: 0.4176 - accuracy: 0.7955 - val_loss: 0.3873 - val_accuracy: 0.8187\n",
      "Epoch 52/100\n",
      "6572/6572 [==============================] - 0s 16us/sample - loss: 0.4128 - accuracy: 0.8004 - val_loss: 0.3853 - val_accuracy: 0.8187\n",
      "Epoch 53/100\n",
      "6572/6572 [==============================] - 0s 18us/sample - loss: 0.4076 - accuracy: 0.8052 - val_loss: 0.3835 - val_accuracy: 0.8187\n",
      "Epoch 54/100\n",
      "6572/6572 [==============================] - 0s 21us/sample - loss: 0.4078 - accuracy: 0.8007 - val_loss: 0.3817 - val_accuracy: 0.8200\n",
      "Epoch 55/100\n",
      "6572/6572 [==============================] - 0s 24us/sample - loss: 0.4046 - accuracy: 0.8034 - val_loss: 0.3807 - val_accuracy: 0.8273\n",
      "Epoch 56/100\n",
      "6572/6572 [==============================] - 0s 20us/sample - loss: 0.4045 - accuracy: 0.8008 - val_loss: 0.3803 - val_accuracy: 0.8230\n",
      "Epoch 57/100\n",
      "6572/6572 [==============================] - 0s 17us/sample - loss: 0.4069 - accuracy: 0.8020 - val_loss: 0.3797 - val_accuracy: 0.8230\n",
      "Epoch 58/100\n",
      "6572/6572 [==============================] - 0s 21us/sample - loss: 0.3985 - accuracy: 0.8072 - val_loss: 0.3788 - val_accuracy: 0.8218\n",
      "Epoch 59/100\n",
      "6572/6572 [==============================] - 0s 22us/sample - loss: 0.3996 - accuracy: 0.8081 - val_loss: 0.3787 - val_accuracy: 0.8218\n",
      "Epoch 60/100\n",
      "6572/6572 [==============================] - 0s 15us/sample - loss: 0.4098 - accuracy: 0.7982 - val_loss: 0.3786 - val_accuracy: 0.8193\n",
      "Epoch 61/100\n",
      "6572/6572 [==============================] - 0s 22us/sample - loss: 0.4055 - accuracy: 0.8058 - val_loss: 0.3796 - val_accuracy: 0.8157\n",
      "Epoch 62/100\n",
      "6572/6572 [==============================] - 0s 18us/sample - loss: 0.4035 - accuracy: 0.8061 - val_loss: 0.3784 - val_accuracy: 0.8181\n",
      "Epoch 63/100\n",
      "6572/6572 [==============================] - 0s 16us/sample - loss: 0.3997 - accuracy: 0.8107 - val_loss: 0.3765 - val_accuracy: 0.8206\n",
      "Epoch 64/100\n",
      "6572/6572 [==============================] - 0s 14us/sample - loss: 0.4026 - accuracy: 0.8025 - val_loss: 0.3748 - val_accuracy: 0.8273\n",
      "Epoch 65/100\n",
      "6572/6572 [==============================] - 0s 14us/sample - loss: 0.3988 - accuracy: 0.8045 - val_loss: 0.3743 - val_accuracy: 0.8273\n",
      "Epoch 66/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.3946 - accuracy: 0.8066 - val_loss: 0.3749 - val_accuracy: 0.8266\n",
      "Epoch 67/100\n",
      "6572/6572 [==============================] - 0s 15us/sample - loss: 0.4034 - accuracy: 0.8055 - val_loss: 0.3739 - val_accuracy: 0.8273\n",
      "Epoch 68/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3942 - accuracy: 0.8036 - val_loss: 0.3754 - val_accuracy: 0.8297\n",
      "Epoch 69/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3993 - accuracy: 0.8048 - val_loss: 0.3754 - val_accuracy: 0.8291\n",
      "Epoch 70/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3932 - accuracy: 0.8118 - val_loss: 0.3746 - val_accuracy: 0.8279\n",
      "Epoch 71/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3959 - accuracy: 0.8112 - val_loss: 0.3744 - val_accuracy: 0.8303\n",
      "Epoch 72/100\n",
      "6572/6572 [==============================] - 0s 8us/sample - loss: 0.3934 - accuracy: 0.8115 - val_loss: 0.3737 - val_accuracy: 0.8279\n",
      "Epoch 73/100\n",
      "6572/6572 [==============================] - 0s 8us/sample - loss: 0.3994 - accuracy: 0.8057 - val_loss: 0.3730 - val_accuracy: 0.8279\n",
      "Epoch 74/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3884 - accuracy: 0.8154 - val_loss: 0.3726 - val_accuracy: 0.8273\n",
      "Epoch 75/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3897 - accuracy: 0.8138 - val_loss: 0.3718 - val_accuracy: 0.8260\n",
      "Epoch 76/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3959 - accuracy: 0.8087 - val_loss: 0.3711 - val_accuracy: 0.8273\n",
      "Epoch 77/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3915 - accuracy: 0.8116 - val_loss: 0.3721 - val_accuracy: 0.8248\n",
      "Epoch 78/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3930 - accuracy: 0.8095 - val_loss: 0.3732 - val_accuracy: 0.8309\n",
      "Epoch 79/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3893 - accuracy: 0.8124 - val_loss: 0.3725 - val_accuracy: 0.8327\n",
      "Epoch 80/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3888 - accuracy: 0.8095 - val_loss: 0.3708 - val_accuracy: 0.8345\n",
      "Epoch 81/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3881 - accuracy: 0.8090 - val_loss: 0.3704 - val_accuracy: 0.8266\n",
      "Epoch 82/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3907 - accuracy: 0.8133 - val_loss: 0.3742 - val_accuracy: 0.8224\n",
      "Epoch 83/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3843 - accuracy: 0.8103 - val_loss: 0.3739 - val_accuracy: 0.8266\n",
      "Epoch 84/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3826 - accuracy: 0.8197 - val_loss: 0.3725 - val_accuracy: 0.8254\n",
      "Epoch 85/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3852 - accuracy: 0.8106 - val_loss: 0.3688 - val_accuracy: 0.8327\n",
      "Epoch 86/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3807 - accuracy: 0.8157 - val_loss: 0.3687 - val_accuracy: 0.8297\n",
      "Epoch 87/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3870 - accuracy: 0.8139 - val_loss: 0.3688 - val_accuracy: 0.8266\n",
      "Epoch 88/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3876 - accuracy: 0.8142 - val_loss: 0.3685 - val_accuracy: 0.8285\n",
      "Epoch 89/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3855 - accuracy: 0.8157 - val_loss: 0.3671 - val_accuracy: 0.8297\n",
      "Epoch 90/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3878 - accuracy: 0.8157 - val_loss: 0.3664 - val_accuracy: 0.8309\n",
      "Epoch 91/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3888 - accuracy: 0.8106 - val_loss: 0.3677 - val_accuracy: 0.8333\n",
      "Epoch 92/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3847 - accuracy: 0.8144 - val_loss: 0.3684 - val_accuracy: 0.8339\n",
      "Epoch 93/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3829 - accuracy: 0.8147 - val_loss: 0.3719 - val_accuracy: 0.8358\n",
      "Epoch 94/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3869 - accuracy: 0.8100 - val_loss: 0.3715 - val_accuracy: 0.8333\n",
      "Epoch 95/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3778 - accuracy: 0.8160 - val_loss: 0.3695 - val_accuracy: 0.8309\n",
      "Epoch 96/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3863 - accuracy: 0.8148 - val_loss: 0.3686 - val_accuracy: 0.8285\n",
      "Epoch 97/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3805 - accuracy: 0.8194 - val_loss: 0.3676 - val_accuracy: 0.8291\n",
      "Epoch 98/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3818 - accuracy: 0.8130 - val_loss: 0.3656 - val_accuracy: 0.8285\n",
      "Epoch 99/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3818 - accuracy: 0.8124 - val_loss: 0.3644 - val_accuracy: 0.8315\n",
      "Epoch 100/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3796 - accuracy: 0.8203 - val_loss: 0.3626 - val_accuracy: 0.8345\n",
      "Feature Space:  (6572, 9)\n",
      "Train on 6572 samples, validate on 1644 samples\n",
      "Epoch 1/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3787 - accuracy: 0.8125 - val_loss: 0.3432 - val_accuracy: 0.8370\n",
      "Epoch 2/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3763 - accuracy: 0.8142 - val_loss: 0.3437 - val_accuracy: 0.8345\n",
      "Epoch 3/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3822 - accuracy: 0.8154 - val_loss: 0.3435 - val_accuracy: 0.8339\n",
      "Epoch 4/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3733 - accuracy: 0.8220 - val_loss: 0.3447 - val_accuracy: 0.8358\n",
      "Epoch 5/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3783 - accuracy: 0.8194 - val_loss: 0.3448 - val_accuracy: 0.8333\n",
      "Epoch 6/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3824 - accuracy: 0.8124 - val_loss: 0.3441 - val_accuracy: 0.8352\n",
      "Epoch 7/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3795 - accuracy: 0.8163 - val_loss: 0.3432 - val_accuracy: 0.8339\n",
      "Epoch 8/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3748 - accuracy: 0.8214 - val_loss: 0.3421 - val_accuracy: 0.8333\n",
      "Epoch 9/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3721 - accuracy: 0.8194 - val_loss: 0.3412 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3755 - accuracy: 0.8171 - val_loss: 0.3411 - val_accuracy: 0.8339\n",
      "Epoch 11/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3713 - accuracy: 0.8211 - val_loss: 0.3406 - val_accuracy: 0.8345\n",
      "Epoch 12/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3721 - accuracy: 0.8194 - val_loss: 0.3405 - val_accuracy: 0.8364\n",
      "Epoch 13/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3743 - accuracy: 0.8180 - val_loss: 0.3402 - val_accuracy: 0.8376\n",
      "Epoch 14/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3774 - accuracy: 0.8186 - val_loss: 0.3409 - val_accuracy: 0.8345\n",
      "Epoch 15/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3753 - accuracy: 0.8223 - val_loss: 0.3408 - val_accuracy: 0.8358\n",
      "Epoch 16/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3743 - accuracy: 0.8174 - val_loss: 0.3405 - val_accuracy: 0.8358\n",
      "Epoch 17/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3703 - accuracy: 0.8227 - val_loss: 0.3399 - val_accuracy: 0.8358\n",
      "Epoch 18/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3699 - accuracy: 0.8192 - val_loss: 0.3402 - val_accuracy: 0.8352\n",
      "Epoch 19/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3743 - accuracy: 0.8243 - val_loss: 0.3396 - val_accuracy: 0.8370\n",
      "Epoch 20/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3752 - accuracy: 0.8171 - val_loss: 0.3398 - val_accuracy: 0.8358\n",
      "Epoch 21/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3710 - accuracy: 0.8189 - val_loss: 0.3396 - val_accuracy: 0.8388\n",
      "Epoch 22/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3733 - accuracy: 0.8206 - val_loss: 0.3396 - val_accuracy: 0.8352\n",
      "Epoch 23/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3749 - accuracy: 0.8201 - val_loss: 0.3390 - val_accuracy: 0.8345\n",
      "Epoch 24/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3753 - accuracy: 0.8165 - val_loss: 0.3383 - val_accuracy: 0.8352\n",
      "Epoch 25/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3722 - accuracy: 0.8189 - val_loss: 0.3390 - val_accuracy: 0.8333\n",
      "Epoch 26/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3749 - accuracy: 0.8179 - val_loss: 0.3385 - val_accuracy: 0.8321\n",
      "Epoch 27/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3698 - accuracy: 0.8303 - val_loss: 0.3396 - val_accuracy: 0.8394\n",
      "Epoch 28/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3760 - accuracy: 0.8206 - val_loss: 0.3389 - val_accuracy: 0.8382\n",
      "Epoch 29/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3696 - accuracy: 0.8211 - val_loss: 0.3406 - val_accuracy: 0.8358\n",
      "Epoch 30/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3689 - accuracy: 0.8160 - val_loss: 0.3397 - val_accuracy: 0.8364\n",
      "Epoch 31/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3634 - accuracy: 0.8261 - val_loss: 0.3397 - val_accuracy: 0.8364\n",
      "Epoch 32/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3673 - accuracy: 0.8271 - val_loss: 0.3385 - val_accuracy: 0.8345\n",
      "Epoch 33/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3719 - accuracy: 0.8235 - val_loss: 0.3400 - val_accuracy: 0.8358\n",
      "Epoch 34/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3683 - accuracy: 0.8240 - val_loss: 0.3392 - val_accuracy: 0.8327\n",
      "Epoch 35/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3660 - accuracy: 0.8273 - val_loss: 0.3372 - val_accuracy: 0.8358\n",
      "Epoch 36/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3635 - accuracy: 0.8270 - val_loss: 0.3366 - val_accuracy: 0.8352\n",
      "Epoch 37/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3698 - accuracy: 0.8201 - val_loss: 0.3366 - val_accuracy: 0.8388\n",
      "Epoch 38/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3686 - accuracy: 0.8191 - val_loss: 0.3394 - val_accuracy: 0.8425\n",
      "Epoch 39/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3710 - accuracy: 0.8173 - val_loss: 0.3375 - val_accuracy: 0.8412\n",
      "Epoch 40/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3671 - accuracy: 0.8217 - val_loss: 0.3356 - val_accuracy: 0.8364\n",
      "Epoch 41/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3654 - accuracy: 0.8220 - val_loss: 0.3368 - val_accuracy: 0.8388\n",
      "Epoch 42/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3676 - accuracy: 0.8261 - val_loss: 0.3390 - val_accuracy: 0.8418\n",
      "Epoch 43/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3748 - accuracy: 0.8153 - val_loss: 0.3427 - val_accuracy: 0.8431\n",
      "Epoch 44/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3739 - accuracy: 0.8180 - val_loss: 0.3395 - val_accuracy: 0.8418\n",
      "Epoch 45/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3648 - accuracy: 0.8270 - val_loss: 0.3390 - val_accuracy: 0.8327\n",
      "Epoch 46/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3648 - accuracy: 0.8316 - val_loss: 0.3382 - val_accuracy: 0.8321\n",
      "Epoch 47/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3699 - accuracy: 0.8267 - val_loss: 0.3367 - val_accuracy: 0.8339\n",
      "Epoch 48/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3700 - accuracy: 0.8201 - val_loss: 0.3359 - val_accuracy: 0.8333\n",
      "Epoch 49/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3690 - accuracy: 0.8262 - val_loss: 0.3352 - val_accuracy: 0.8352\n",
      "Epoch 50/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3674 - accuracy: 0.8262 - val_loss: 0.3344 - val_accuracy: 0.8364\n",
      "Epoch 51/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3700 - accuracy: 0.8209 - val_loss: 0.3343 - val_accuracy: 0.8352\n",
      "Epoch 52/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3666 - accuracy: 0.8255 - val_loss: 0.3352 - val_accuracy: 0.8364\n",
      "Epoch 53/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3652 - accuracy: 0.8220 - val_loss: 0.3353 - val_accuracy: 0.8345\n",
      "Epoch 54/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3647 - accuracy: 0.8267 - val_loss: 0.3352 - val_accuracy: 0.8339\n",
      "Epoch 55/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3585 - accuracy: 0.8244 - val_loss: 0.3350 - val_accuracy: 0.8352\n",
      "Epoch 56/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3658 - accuracy: 0.8296 - val_loss: 0.3347 - val_accuracy: 0.8364\n",
      "Epoch 57/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3635 - accuracy: 0.8256 - val_loss: 0.3346 - val_accuracy: 0.8364\n",
      "Epoch 58/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3606 - accuracy: 0.8313 - val_loss: 0.3347 - val_accuracy: 0.8382\n",
      "Epoch 59/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3583 - accuracy: 0.8282 - val_loss: 0.3344 - val_accuracy: 0.8376\n",
      "Epoch 60/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3597 - accuracy: 0.8278 - val_loss: 0.3343 - val_accuracy: 0.8358\n",
      "Epoch 61/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3593 - accuracy: 0.8296 - val_loss: 0.3336 - val_accuracy: 0.8345\n",
      "Epoch 62/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3612 - accuracy: 0.8306 - val_loss: 0.3328 - val_accuracy: 0.8376\n",
      "Epoch 63/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3601 - accuracy: 0.8276 - val_loss: 0.3321 - val_accuracy: 0.8364\n",
      "Epoch 64/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3660 - accuracy: 0.8227 - val_loss: 0.3321 - val_accuracy: 0.8358\n",
      "Epoch 65/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3611 - accuracy: 0.8235 - val_loss: 0.3319 - val_accuracy: 0.8358\n",
      "Epoch 66/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3595 - accuracy: 0.8265 - val_loss: 0.3323 - val_accuracy: 0.8352\n",
      "Epoch 67/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3661 - accuracy: 0.8249 - val_loss: 0.3328 - val_accuracy: 0.8345\n",
      "Epoch 68/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3567 - accuracy: 0.8299 - val_loss: 0.3354 - val_accuracy: 0.8400\n",
      "Epoch 69/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3677 - accuracy: 0.8229 - val_loss: 0.3348 - val_accuracy: 0.8388\n",
      "Epoch 70/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3605 - accuracy: 0.8230 - val_loss: 0.3337 - val_accuracy: 0.8364\n",
      "Epoch 71/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3608 - accuracy: 0.8238 - val_loss: 0.3342 - val_accuracy: 0.8345\n",
      "Epoch 72/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3619 - accuracy: 0.8276 - val_loss: 0.3353 - val_accuracy: 0.8370\n",
      "Epoch 73/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3660 - accuracy: 0.8279 - val_loss: 0.3347 - val_accuracy: 0.8370\n",
      "Epoch 74/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3662 - accuracy: 0.8270 - val_loss: 0.3356 - val_accuracy: 0.8370\n",
      "Epoch 75/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3627 - accuracy: 0.8265 - val_loss: 0.3344 - val_accuracy: 0.8382\n",
      "Epoch 76/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3619 - accuracy: 0.8243 - val_loss: 0.3330 - val_accuracy: 0.8388\n",
      "Epoch 77/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3618 - accuracy: 0.8259 - val_loss: 0.3339 - val_accuracy: 0.8388\n",
      "Epoch 78/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3594 - accuracy: 0.8258 - val_loss: 0.3338 - val_accuracy: 0.8400\n",
      "Epoch 79/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3623 - accuracy: 0.8240 - val_loss: 0.3324 - val_accuracy: 0.8370\n",
      "Epoch 80/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3601 - accuracy: 0.8306 - val_loss: 0.3320 - val_accuracy: 0.8370\n",
      "Epoch 81/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3578 - accuracy: 0.8294 - val_loss: 0.3333 - val_accuracy: 0.8364\n",
      "Epoch 82/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3587 - accuracy: 0.8328 - val_loss: 0.3331 - val_accuracy: 0.8370\n",
      "Epoch 83/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3599 - accuracy: 0.8296 - val_loss: 0.3324 - val_accuracy: 0.8388\n",
      "Epoch 84/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3574 - accuracy: 0.8320 - val_loss: 0.3339 - val_accuracy: 0.8370\n",
      "Epoch 85/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3571 - accuracy: 0.8290 - val_loss: 0.3343 - val_accuracy: 0.8376\n",
      "Epoch 86/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3578 - accuracy: 0.8267 - val_loss: 0.3342 - val_accuracy: 0.8382\n",
      "Epoch 87/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3574 - accuracy: 0.8290 - val_loss: 0.3351 - val_accuracy: 0.8309\n",
      "Epoch 88/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3621 - accuracy: 0.8265 - val_loss: 0.3365 - val_accuracy: 0.8309\n",
      "Epoch 89/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3594 - accuracy: 0.8317 - val_loss: 0.3357 - val_accuracy: 0.8321\n",
      "Epoch 90/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3576 - accuracy: 0.8314 - val_loss: 0.3348 - val_accuracy: 0.8327\n",
      "Epoch 91/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3594 - accuracy: 0.8262 - val_loss: 0.3338 - val_accuracy: 0.8352\n",
      "Epoch 92/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3622 - accuracy: 0.8273 - val_loss: 0.3322 - val_accuracy: 0.8400\n",
      "Epoch 93/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3559 - accuracy: 0.8297 - val_loss: 0.3316 - val_accuracy: 0.8406\n",
      "Epoch 94/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3562 - accuracy: 0.8291 - val_loss: 0.3321 - val_accuracy: 0.8388\n",
      "Epoch 95/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3573 - accuracy: 0.8296 - val_loss: 0.3327 - val_accuracy: 0.8376\n",
      "Epoch 96/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3544 - accuracy: 0.8297 - val_loss: 0.3337 - val_accuracy: 0.8388\n",
      "Epoch 97/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3622 - accuracy: 0.8273 - val_loss: 0.3337 - val_accuracy: 0.8382\n",
      "Epoch 98/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3558 - accuracy: 0.8311 - val_loss: 0.3329 - val_accuracy: 0.8370\n",
      "Epoch 99/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3582 - accuracy: 0.8360 - val_loss: 0.3324 - val_accuracy: 0.8376\n",
      "Epoch 100/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3504 - accuracy: 0.8348 - val_loss: 0.3326 - val_accuracy: 0.8412\n",
      "Feature Space:  (6572, 9)\n",
      "Train on 6572 samples, validate on 1644 samples\n",
      "Epoch 1/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3463 - accuracy: 0.8372 - val_loss: 0.3319 - val_accuracy: 0.8485\n",
      "Epoch 2/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3479 - accuracy: 0.8393 - val_loss: 0.3311 - val_accuracy: 0.8491\n",
      "Epoch 3/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3439 - accuracy: 0.8446 - val_loss: 0.3313 - val_accuracy: 0.8479\n",
      "Epoch 4/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3444 - accuracy: 0.8436 - val_loss: 0.3319 - val_accuracy: 0.8479\n",
      "Epoch 5/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3487 - accuracy: 0.8392 - val_loss: 0.3348 - val_accuracy: 0.8406\n",
      "Epoch 6/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3434 - accuracy: 0.8463 - val_loss: 0.3349 - val_accuracy: 0.8400\n",
      "Epoch 7/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3466 - accuracy: 0.8404 - val_loss: 0.3341 - val_accuracy: 0.8394\n",
      "Epoch 8/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3384 - accuracy: 0.8427 - val_loss: 0.3345 - val_accuracy: 0.8370\n",
      "Epoch 9/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3415 - accuracy: 0.8428 - val_loss: 0.3345 - val_accuracy: 0.8406\n",
      "Epoch 10/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3442 - accuracy: 0.8375 - val_loss: 0.3337 - val_accuracy: 0.8394\n",
      "Epoch 11/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3434 - accuracy: 0.8430 - val_loss: 0.3331 - val_accuracy: 0.8412\n",
      "Epoch 12/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3418 - accuracy: 0.8399 - val_loss: 0.3325 - val_accuracy: 0.8431\n",
      "Epoch 13/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3427 - accuracy: 0.8413 - val_loss: 0.3330 - val_accuracy: 0.8443\n",
      "Epoch 14/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3446 - accuracy: 0.8375 - val_loss: 0.3328 - val_accuracy: 0.8461\n",
      "Epoch 15/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3381 - accuracy: 0.8445 - val_loss: 0.3335 - val_accuracy: 0.8461\n",
      "Epoch 16/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3467 - accuracy: 0.8372 - val_loss: 0.3345 - val_accuracy: 0.8455\n",
      "Epoch 17/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3438 - accuracy: 0.8389 - val_loss: 0.3332 - val_accuracy: 0.8467\n",
      "Epoch 18/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3401 - accuracy: 0.8425 - val_loss: 0.3323 - val_accuracy: 0.8461\n",
      "Epoch 19/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3388 - accuracy: 0.8407 - val_loss: 0.3325 - val_accuracy: 0.8425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3371 - accuracy: 0.8471 - val_loss: 0.3321 - val_accuracy: 0.8437\n",
      "Epoch 21/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3378 - accuracy: 0.8443 - val_loss: 0.3313 - val_accuracy: 0.8498\n",
      "Epoch 22/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3413 - accuracy: 0.8427 - val_loss: 0.3313 - val_accuracy: 0.8498\n",
      "Epoch 23/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3400 - accuracy: 0.8449 - val_loss: 0.3315 - val_accuracy: 0.8504\n",
      "Epoch 24/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3429 - accuracy: 0.8405 - val_loss: 0.3314 - val_accuracy: 0.8467\n",
      "Epoch 25/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3392 - accuracy: 0.8440 - val_loss: 0.3339 - val_accuracy: 0.8406\n",
      "Epoch 26/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3403 - accuracy: 0.8463 - val_loss: 0.3342 - val_accuracy: 0.8412\n",
      "Epoch 27/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3436 - accuracy: 0.8418 - val_loss: 0.3329 - val_accuracy: 0.8449\n",
      "Epoch 28/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3318 - accuracy: 0.8424 - val_loss: 0.3326 - val_accuracy: 0.8473\n",
      "Epoch 29/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3361 - accuracy: 0.8457 - val_loss: 0.3332 - val_accuracy: 0.8437\n",
      "Epoch 30/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3376 - accuracy: 0.8449 - val_loss: 0.3349 - val_accuracy: 0.8412\n",
      "Epoch 31/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3421 - accuracy: 0.8416 - val_loss: 0.3375 - val_accuracy: 0.8394\n",
      "Epoch 32/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3459 - accuracy: 0.8410 - val_loss: 0.3365 - val_accuracy: 0.8394\n",
      "Epoch 33/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3355 - accuracy: 0.8459 - val_loss: 0.3353 - val_accuracy: 0.8382\n",
      "Epoch 34/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3393 - accuracy: 0.8405 - val_loss: 0.3358 - val_accuracy: 0.8394\n",
      "Epoch 35/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3372 - accuracy: 0.8468 - val_loss: 0.3361 - val_accuracy: 0.8412\n",
      "Epoch 36/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3397 - accuracy: 0.8430 - val_loss: 0.3356 - val_accuracy: 0.8418\n",
      "Epoch 37/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3384 - accuracy: 0.8456 - val_loss: 0.3351 - val_accuracy: 0.8425\n",
      "Epoch 38/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3356 - accuracy: 0.8436 - val_loss: 0.3346 - val_accuracy: 0.8437\n",
      "Epoch 39/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3365 - accuracy: 0.8466 - val_loss: 0.3343 - val_accuracy: 0.8425\n",
      "Epoch 40/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3393 - accuracy: 0.8468 - val_loss: 0.3337 - val_accuracy: 0.8449\n",
      "Epoch 41/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3328 - accuracy: 0.8465 - val_loss: 0.3328 - val_accuracy: 0.8479\n",
      "Epoch 42/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3322 - accuracy: 0.8488 - val_loss: 0.3321 - val_accuracy: 0.8467\n",
      "Epoch 43/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3374 - accuracy: 0.8453 - val_loss: 0.3319 - val_accuracy: 0.8473\n",
      "Epoch 44/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3340 - accuracy: 0.8475 - val_loss: 0.3320 - val_accuracy: 0.8467\n",
      "Epoch 45/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3358 - accuracy: 0.8469 - val_loss: 0.3317 - val_accuracy: 0.8461\n",
      "Epoch 46/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3355 - accuracy: 0.8465 - val_loss: 0.3326 - val_accuracy: 0.8443\n",
      "Epoch 47/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3340 - accuracy: 0.8480 - val_loss: 0.3326 - val_accuracy: 0.8449\n",
      "Epoch 48/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3368 - accuracy: 0.8463 - val_loss: 0.3334 - val_accuracy: 0.8473\n",
      "Epoch 49/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3334 - accuracy: 0.8460 - val_loss: 0.3342 - val_accuracy: 0.8455\n",
      "Epoch 50/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3371 - accuracy: 0.8449 - val_loss: 0.3336 - val_accuracy: 0.8473\n",
      "Epoch 51/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3374 - accuracy: 0.8466 - val_loss: 0.3334 - val_accuracy: 0.8485\n",
      "Epoch 52/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3381 - accuracy: 0.8451 - val_loss: 0.3329 - val_accuracy: 0.8485\n",
      "Epoch 53/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3365 - accuracy: 0.8462 - val_loss: 0.3320 - val_accuracy: 0.8461\n",
      "Epoch 54/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3350 - accuracy: 0.8481 - val_loss: 0.3319 - val_accuracy: 0.8461\n",
      "Epoch 55/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3371 - accuracy: 0.8466 - val_loss: 0.3307 - val_accuracy: 0.8449\n",
      "Epoch 56/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3375 - accuracy: 0.8436 - val_loss: 0.3305 - val_accuracy: 0.8449\n",
      "Epoch 57/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3404 - accuracy: 0.8449 - val_loss: 0.3317 - val_accuracy: 0.8443\n",
      "Epoch 58/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3398 - accuracy: 0.8414 - val_loss: 0.3294 - val_accuracy: 0.8461\n",
      "Epoch 59/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3364 - accuracy: 0.8469 - val_loss: 0.3293 - val_accuracy: 0.8498\n",
      "Epoch 60/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3388 - accuracy: 0.8430 - val_loss: 0.3296 - val_accuracy: 0.8491\n",
      "Epoch 61/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3366 - accuracy: 0.8451 - val_loss: 0.3294 - val_accuracy: 0.8473\n",
      "Epoch 62/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3312 - accuracy: 0.8456 - val_loss: 0.3296 - val_accuracy: 0.8504\n",
      "Epoch 63/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3368 - accuracy: 0.8418 - val_loss: 0.3308 - val_accuracy: 0.8504\n",
      "Epoch 64/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3355 - accuracy: 0.8428 - val_loss: 0.3312 - val_accuracy: 0.8491\n",
      "Epoch 65/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3313 - accuracy: 0.8484 - val_loss: 0.3310 - val_accuracy: 0.8485\n",
      "Epoch 66/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3332 - accuracy: 0.8448 - val_loss: 0.3314 - val_accuracy: 0.8473\n",
      "Epoch 67/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3350 - accuracy: 0.8471 - val_loss: 0.3315 - val_accuracy: 0.8449\n",
      "Epoch 68/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3379 - accuracy: 0.8422 - val_loss: 0.3311 - val_accuracy: 0.8449\n",
      "Epoch 69/100\n",
      "6572/6572 [==============================] - 0s 16us/sample - loss: 0.3340 - accuracy: 0.8469 - val_loss: 0.3308 - val_accuracy: 0.8425\n",
      "Epoch 70/100\n",
      "6572/6572 [==============================] - 0s 17us/sample - loss: 0.3345 - accuracy: 0.8491 - val_loss: 0.3307 - val_accuracy: 0.8425\n",
      "Epoch 71/100\n",
      "6572/6572 [==============================] - 0s 15us/sample - loss: 0.3311 - accuracy: 0.8481 - val_loss: 0.3311 - val_accuracy: 0.8473\n",
      "Epoch 72/100\n",
      "6572/6572 [==============================] - 0s 8us/sample - loss: 0.3307 - accuracy: 0.8480 - val_loss: 0.3315 - val_accuracy: 0.8461\n",
      "Epoch 73/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3338 - accuracy: 0.8419 - val_loss: 0.3310 - val_accuracy: 0.8467\n",
      "Epoch 74/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3338 - accuracy: 0.8477 - val_loss: 0.3309 - val_accuracy: 0.8485\n",
      "Epoch 75/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3288 - accuracy: 0.8519 - val_loss: 0.3309 - val_accuracy: 0.8479\n",
      "Epoch 76/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3341 - accuracy: 0.8460 - val_loss: 0.3309 - val_accuracy: 0.8455\n",
      "Epoch 77/100\n",
      "6572/6572 [==============================] - 0s 8us/sample - loss: 0.3375 - accuracy: 0.8463 - val_loss: 0.3315 - val_accuracy: 0.8443\n",
      "Epoch 78/100\n",
      "6572/6572 [==============================] - 0s 8us/sample - loss: 0.3319 - accuracy: 0.8463 - val_loss: 0.3303 - val_accuracy: 0.8461\n",
      "Epoch 79/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3389 - accuracy: 0.8427 - val_loss: 0.3306 - val_accuracy: 0.8479\n",
      "Epoch 80/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3354 - accuracy: 0.8439 - val_loss: 0.3330 - val_accuracy: 0.8461\n",
      "Epoch 81/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3388 - accuracy: 0.8401 - val_loss: 0.3320 - val_accuracy: 0.8461\n",
      "Epoch 82/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3356 - accuracy: 0.8427 - val_loss: 0.3306 - val_accuracy: 0.8455\n",
      "Epoch 83/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3306 - accuracy: 0.8471 - val_loss: 0.3305 - val_accuracy: 0.8443\n",
      "Epoch 84/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3336 - accuracy: 0.8422 - val_loss: 0.3308 - val_accuracy: 0.8443\n",
      "Epoch 85/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3340 - accuracy: 0.8484 - val_loss: 0.3313 - val_accuracy: 0.8431\n",
      "Epoch 86/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3346 - accuracy: 0.8453 - val_loss: 0.3313 - val_accuracy: 0.8418\n",
      "Epoch 87/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3305 - accuracy: 0.8439 - val_loss: 0.3313 - val_accuracy: 0.8449\n",
      "Epoch 88/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3280 - accuracy: 0.8515 - val_loss: 0.3319 - val_accuracy: 0.8455\n",
      "Epoch 89/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3320 - accuracy: 0.8486 - val_loss: 0.3321 - val_accuracy: 0.8449\n",
      "Epoch 90/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3314 - accuracy: 0.8456 - val_loss: 0.3316 - val_accuracy: 0.8449\n",
      "Epoch 91/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3334 - accuracy: 0.8469 - val_loss: 0.3316 - val_accuracy: 0.8467\n",
      "Epoch 92/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3354 - accuracy: 0.8442 - val_loss: 0.3317 - val_accuracy: 0.8485\n",
      "Epoch 93/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3304 - accuracy: 0.8463 - val_loss: 0.3314 - val_accuracy: 0.8485\n",
      "Epoch 94/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.3282 - accuracy: 0.8488 - val_loss: 0.3314 - val_accuracy: 0.8479\n",
      "Epoch 95/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3294 - accuracy: 0.8488 - val_loss: 0.3315 - val_accuracy: 0.8461\n",
      "Epoch 96/100\n",
      "6572/6572 [==============================] - 0s 16us/sample - loss: 0.3280 - accuracy: 0.8449 - val_loss: 0.3314 - val_accuracy: 0.8467\n",
      "Epoch 97/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.3328 - accuracy: 0.8513 - val_loss: 0.3339 - val_accuracy: 0.8461\n",
      "Epoch 98/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3364 - accuracy: 0.8472 - val_loss: 0.3342 - val_accuracy: 0.8443\n",
      "Epoch 99/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3392 - accuracy: 0.8454 - val_loss: 0.3306 - val_accuracy: 0.8443\n",
      "Epoch 100/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3341 - accuracy: 0.8477 - val_loss: 0.3302 - val_accuracy: 0.8461\n",
      "Feature Space:  (6572, 9)\n",
      "Train on 6572 samples, validate on 1644 samples\n",
      "Epoch 1/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3524 - accuracy: 0.8366 - val_loss: 0.3332 - val_accuracy: 0.8412\n",
      "Epoch 2/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3480 - accuracy: 0.8361 - val_loss: 0.3334 - val_accuracy: 0.8406\n",
      "Epoch 3/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3513 - accuracy: 0.8340 - val_loss: 0.3331 - val_accuracy: 0.8394\n",
      "Epoch 4/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3519 - accuracy: 0.8305 - val_loss: 0.3328 - val_accuracy: 0.8400\n",
      "Epoch 5/100\n",
      "6572/6572 [==============================] - 0s 8us/sample - loss: 0.3481 - accuracy: 0.8338 - val_loss: 0.3322 - val_accuracy: 0.8431\n",
      "Epoch 6/100\n",
      "6572/6572 [==============================] - 0s 8us/sample - loss: 0.3515 - accuracy: 0.8349 - val_loss: 0.3324 - val_accuracy: 0.8425\n",
      "Epoch 7/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3516 - accuracy: 0.8367 - val_loss: 0.3341 - val_accuracy: 0.8412\n",
      "Epoch 8/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3512 - accuracy: 0.8316 - val_loss: 0.3335 - val_accuracy: 0.8431\n",
      "Epoch 9/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3510 - accuracy: 0.8340 - val_loss: 0.3323 - val_accuracy: 0.8443\n",
      "Epoch 10/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3490 - accuracy: 0.8404 - val_loss: 0.3320 - val_accuracy: 0.8418\n",
      "Epoch 11/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.3467 - accuracy: 0.8363 - val_loss: 0.3322 - val_accuracy: 0.8418\n",
      "Epoch 12/100\n",
      "6572/6572 [==============================] - 0s 15us/sample - loss: 0.3512 - accuracy: 0.8332 - val_loss: 0.3330 - val_accuracy: 0.8406\n",
      "Epoch 13/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3478 - accuracy: 0.8411 - val_loss: 0.3325 - val_accuracy: 0.8394\n",
      "Epoch 14/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3505 - accuracy: 0.8360 - val_loss: 0.3319 - val_accuracy: 0.8394\n",
      "Epoch 15/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3484 - accuracy: 0.8375 - val_loss: 0.3315 - val_accuracy: 0.8455\n",
      "Epoch 16/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3466 - accuracy: 0.8364 - val_loss: 0.3312 - val_accuracy: 0.8443\n",
      "Epoch 17/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3465 - accuracy: 0.8369 - val_loss: 0.3311 - val_accuracy: 0.8431\n",
      "Epoch 18/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3457 - accuracy: 0.8399 - val_loss: 0.3309 - val_accuracy: 0.8455\n",
      "Epoch 19/100\n",
      "6572/6572 [==============================] - 0s 15us/sample - loss: 0.3480 - accuracy: 0.8367 - val_loss: 0.3308 - val_accuracy: 0.8467\n",
      "Epoch 20/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3462 - accuracy: 0.8379 - val_loss: 0.3306 - val_accuracy: 0.8455\n",
      "Epoch 21/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3447 - accuracy: 0.8389 - val_loss: 0.3306 - val_accuracy: 0.8437\n",
      "Epoch 22/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3502 - accuracy: 0.8326 - val_loss: 0.3304 - val_accuracy: 0.8449\n",
      "Epoch 23/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.3465 - accuracy: 0.8341 - val_loss: 0.3302 - val_accuracy: 0.8467\n",
      "Epoch 24/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3477 - accuracy: 0.8344 - val_loss: 0.3304 - val_accuracy: 0.8412\n",
      "Epoch 25/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3467 - accuracy: 0.8372 - val_loss: 0.3304 - val_accuracy: 0.8431\n",
      "Epoch 26/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3448 - accuracy: 0.8373 - val_loss: 0.3301 - val_accuracy: 0.8473\n",
      "Epoch 27/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3480 - accuracy: 0.8389 - val_loss: 0.3300 - val_accuracy: 0.8455\n",
      "Epoch 28/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.3428 - accuracy: 0.8384 - val_loss: 0.3298 - val_accuracy: 0.8437\n",
      "Epoch 29/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.3418 - accuracy: 0.8392 - val_loss: 0.3297 - val_accuracy: 0.8425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3442 - accuracy: 0.8354 - val_loss: 0.3296 - val_accuracy: 0.8437\n",
      "Epoch 31/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3441 - accuracy: 0.8390 - val_loss: 0.3295 - val_accuracy: 0.8461\n",
      "Epoch 32/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3453 - accuracy: 0.8419 - val_loss: 0.3294 - val_accuracy: 0.8461\n",
      "Epoch 33/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3416 - accuracy: 0.8398 - val_loss: 0.3293 - val_accuracy: 0.8473\n",
      "Epoch 34/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3455 - accuracy: 0.8392 - val_loss: 0.3295 - val_accuracy: 0.8437\n",
      "Epoch 35/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3444 - accuracy: 0.8392 - val_loss: 0.3307 - val_accuracy: 0.8418\n",
      "Epoch 36/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3490 - accuracy: 0.8416 - val_loss: 0.3309 - val_accuracy: 0.8431\n",
      "Epoch 37/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3441 - accuracy: 0.8428 - val_loss: 0.3305 - val_accuracy: 0.8406\n",
      "Epoch 38/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3429 - accuracy: 0.8416 - val_loss: 0.3304 - val_accuracy: 0.8418\n",
      "Epoch 39/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3443 - accuracy: 0.8386 - val_loss: 0.3310 - val_accuracy: 0.8412\n",
      "Epoch 40/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3468 - accuracy: 0.8405 - val_loss: 0.3311 - val_accuracy: 0.8406\n",
      "Epoch 41/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3480 - accuracy: 0.8395 - val_loss: 0.3310 - val_accuracy: 0.8431\n",
      "Epoch 42/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3464 - accuracy: 0.8405 - val_loss: 0.3304 - val_accuracy: 0.8425\n",
      "Epoch 43/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3448 - accuracy: 0.8395 - val_loss: 0.3302 - val_accuracy: 0.8418\n",
      "Epoch 44/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3451 - accuracy: 0.8392 - val_loss: 0.3300 - val_accuracy: 0.8431\n",
      "Epoch 45/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3423 - accuracy: 0.8407 - val_loss: 0.3317 - val_accuracy: 0.8418\n",
      "Epoch 46/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3444 - accuracy: 0.8381 - val_loss: 0.3307 - val_accuracy: 0.8431\n",
      "Epoch 47/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3476 - accuracy: 0.8370 - val_loss: 0.3307 - val_accuracy: 0.8382\n",
      "Epoch 48/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3484 - accuracy: 0.8387 - val_loss: 0.3323 - val_accuracy: 0.8364\n",
      "Epoch 49/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3448 - accuracy: 0.8334 - val_loss: 0.3324 - val_accuracy: 0.8376\n",
      "Epoch 50/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3475 - accuracy: 0.8392 - val_loss: 0.3316 - val_accuracy: 0.8364\n",
      "Epoch 51/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3462 - accuracy: 0.8399 - val_loss: 0.3305 - val_accuracy: 0.8370\n",
      "Epoch 52/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3437 - accuracy: 0.8386 - val_loss: 0.3302 - val_accuracy: 0.8418\n",
      "Epoch 53/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3448 - accuracy: 0.8379 - val_loss: 0.3298 - val_accuracy: 0.8418\n",
      "Epoch 54/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3480 - accuracy: 0.8372 - val_loss: 0.3294 - val_accuracy: 0.8437\n",
      "Epoch 55/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3424 - accuracy: 0.8401 - val_loss: 0.3293 - val_accuracy: 0.8437\n",
      "Epoch 56/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3413 - accuracy: 0.8387 - val_loss: 0.3304 - val_accuracy: 0.8455\n",
      "Epoch 57/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3455 - accuracy: 0.8411 - val_loss: 0.3348 - val_accuracy: 0.8406\n",
      "Epoch 58/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3492 - accuracy: 0.8398 - val_loss: 0.3337 - val_accuracy: 0.8437\n",
      "Epoch 59/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3453 - accuracy: 0.8376 - val_loss: 0.3314 - val_accuracy: 0.8431\n",
      "Epoch 60/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3436 - accuracy: 0.8410 - val_loss: 0.3304 - val_accuracy: 0.8455\n",
      "Epoch 61/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3436 - accuracy: 0.8440 - val_loss: 0.3306 - val_accuracy: 0.8443\n",
      "Epoch 62/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3445 - accuracy: 0.8389 - val_loss: 0.3298 - val_accuracy: 0.8437\n",
      "Epoch 63/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3457 - accuracy: 0.8398 - val_loss: 0.3295 - val_accuracy: 0.8449\n",
      "Epoch 64/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3448 - accuracy: 0.8402 - val_loss: 0.3301 - val_accuracy: 0.8437\n",
      "Epoch 65/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3442 - accuracy: 0.8381 - val_loss: 0.3305 - val_accuracy: 0.8418\n",
      "Epoch 66/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3425 - accuracy: 0.8419 - val_loss: 0.3302 - val_accuracy: 0.8406\n",
      "Epoch 67/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3429 - accuracy: 0.8401 - val_loss: 0.3297 - val_accuracy: 0.8443\n",
      "Epoch 68/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3438 - accuracy: 0.8393 - val_loss: 0.3300 - val_accuracy: 0.8412\n",
      "Epoch 69/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3450 - accuracy: 0.8390 - val_loss: 0.3299 - val_accuracy: 0.8412\n",
      "Epoch 70/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3416 - accuracy: 0.8419 - val_loss: 0.3293 - val_accuracy: 0.8443\n",
      "Epoch 71/100\n",
      "6572/6572 [==============================] - 0s 8us/sample - loss: 0.3442 - accuracy: 0.8379 - val_loss: 0.3299 - val_accuracy: 0.8418\n",
      "Epoch 72/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3430 - accuracy: 0.8390 - val_loss: 0.3299 - val_accuracy: 0.8388\n",
      "Epoch 73/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3442 - accuracy: 0.8416 - val_loss: 0.3295 - val_accuracy: 0.8400\n",
      "Epoch 74/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3399 - accuracy: 0.8428 - val_loss: 0.3292 - val_accuracy: 0.8455\n",
      "Epoch 75/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3447 - accuracy: 0.8384 - val_loss: 0.3289 - val_accuracy: 0.8473\n",
      "Epoch 76/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3396 - accuracy: 0.8416 - val_loss: 0.3288 - val_accuracy: 0.8479\n",
      "Epoch 77/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3407 - accuracy: 0.8425 - val_loss: 0.3289 - val_accuracy: 0.8449\n",
      "Epoch 78/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3409 - accuracy: 0.8425 - val_loss: 0.3286 - val_accuracy: 0.8431\n",
      "Epoch 79/100\n",
      "6572/6572 [==============================] - 0s 8us/sample - loss: 0.3417 - accuracy: 0.8373 - val_loss: 0.3285 - val_accuracy: 0.8437\n",
      "Epoch 80/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3422 - accuracy: 0.8414 - val_loss: 0.3290 - val_accuracy: 0.8431\n",
      "Epoch 81/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3416 - accuracy: 0.8407 - val_loss: 0.3289 - val_accuracy: 0.8431\n",
      "Epoch 82/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3335 - accuracy: 0.8459 - val_loss: 0.3287 - val_accuracy: 0.8455\n",
      "Epoch 83/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3449 - accuracy: 0.8361 - val_loss: 0.3288 - val_accuracy: 0.8461\n",
      "Epoch 84/100\n",
      "6572/6572 [==============================] - 0s 14us/sample - loss: 0.3431 - accuracy: 0.8408 - val_loss: 0.3295 - val_accuracy: 0.8461\n",
      "Epoch 85/100\n",
      "6572/6572 [==============================] - 0s 19us/sample - loss: 0.3399 - accuracy: 0.8411 - val_loss: 0.3286 - val_accuracy: 0.8449\n",
      "Epoch 86/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.3436 - accuracy: 0.8370 - val_loss: 0.3285 - val_accuracy: 0.8449\n",
      "Epoch 87/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3402 - accuracy: 0.8427 - val_loss: 0.3289 - val_accuracy: 0.8461\n",
      "Epoch 88/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3392 - accuracy: 0.8427 - val_loss: 0.3287 - val_accuracy: 0.8443\n",
      "Epoch 89/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3416 - accuracy: 0.8433 - val_loss: 0.3281 - val_accuracy: 0.8461\n",
      "Epoch 90/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3420 - accuracy: 0.8421 - val_loss: 0.3282 - val_accuracy: 0.8455\n",
      "Epoch 91/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3432 - accuracy: 0.8430 - val_loss: 0.3280 - val_accuracy: 0.8467\n",
      "Epoch 92/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3451 - accuracy: 0.8389 - val_loss: 0.3278 - val_accuracy: 0.8461\n",
      "Epoch 93/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3432 - accuracy: 0.8407 - val_loss: 0.3277 - val_accuracy: 0.8449\n",
      "Epoch 94/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3437 - accuracy: 0.8418 - val_loss: 0.3277 - val_accuracy: 0.8449\n",
      "Epoch 95/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3437 - accuracy: 0.8407 - val_loss: 0.3276 - val_accuracy: 0.8455\n",
      "Epoch 96/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3425 - accuracy: 0.8401 - val_loss: 0.3274 - val_accuracy: 0.8467\n",
      "Epoch 97/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3389 - accuracy: 0.8419 - val_loss: 0.3278 - val_accuracy: 0.8455\n",
      "Epoch 98/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3426 - accuracy: 0.8389 - val_loss: 0.3271 - val_accuracy: 0.8455\n",
      "Epoch 99/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3421 - accuracy: 0.8422 - val_loss: 0.3270 - val_accuracy: 0.8455\n",
      "Epoch 100/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3417 - accuracy: 0.8407 - val_loss: 0.3270 - val_accuracy: 0.8443\n",
      "Feature Space:  (6572, 9)\n",
      "Train on 6572 samples, validate on 1644 samples\n",
      "Epoch 1/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3589 - accuracy: 0.8375 - val_loss: 0.3286 - val_accuracy: 0.8425\n",
      "Epoch 2/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3529 - accuracy: 0.8378 - val_loss: 0.3284 - val_accuracy: 0.8425\n",
      "Epoch 3/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3598 - accuracy: 0.8338 - val_loss: 0.3283 - val_accuracy: 0.8437\n",
      "Epoch 4/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3551 - accuracy: 0.8360 - val_loss: 0.3284 - val_accuracy: 0.8437\n",
      "Epoch 5/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3554 - accuracy: 0.8348 - val_loss: 0.3283 - val_accuracy: 0.8431\n",
      "Epoch 6/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3542 - accuracy: 0.8346 - val_loss: 0.3281 - val_accuracy: 0.8479\n",
      "Epoch 7/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3570 - accuracy: 0.8370 - val_loss: 0.3288 - val_accuracy: 0.8473\n",
      "Epoch 8/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3477 - accuracy: 0.8352 - val_loss: 0.3291 - val_accuracy: 0.8467\n",
      "Epoch 9/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3563 - accuracy: 0.8341 - val_loss: 0.3290 - val_accuracy: 0.8461\n",
      "Epoch 10/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3483 - accuracy: 0.8373 - val_loss: 0.3287 - val_accuracy: 0.8473\n",
      "Epoch 11/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3560 - accuracy: 0.8328 - val_loss: 0.3300 - val_accuracy: 0.8479\n",
      "Epoch 12/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3501 - accuracy: 0.8393 - val_loss: 0.3321 - val_accuracy: 0.8491\n",
      "Epoch 13/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3548 - accuracy: 0.8367 - val_loss: 0.3348 - val_accuracy: 0.8467\n",
      "Epoch 14/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3525 - accuracy: 0.8331 - val_loss: 0.3333 - val_accuracy: 0.8491\n",
      "Epoch 15/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3595 - accuracy: 0.8328 - val_loss: 0.3318 - val_accuracy: 0.8461\n",
      "Epoch 16/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3556 - accuracy: 0.8346 - val_loss: 0.3336 - val_accuracy: 0.8418\n",
      "Epoch 17/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3542 - accuracy: 0.8332 - val_loss: 0.3345 - val_accuracy: 0.8370\n",
      "Epoch 18/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3510 - accuracy: 0.8360 - val_loss: 0.3365 - val_accuracy: 0.8358\n",
      "Epoch 19/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3576 - accuracy: 0.8306 - val_loss: 0.3359 - val_accuracy: 0.8376\n",
      "Epoch 20/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3565 - accuracy: 0.8358 - val_loss: 0.3331 - val_accuracy: 0.8394\n",
      "Epoch 21/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3467 - accuracy: 0.8348 - val_loss: 0.3325 - val_accuracy: 0.8418\n",
      "Epoch 22/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3515 - accuracy: 0.8360 - val_loss: 0.3319 - val_accuracy: 0.8431\n",
      "Epoch 23/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3480 - accuracy: 0.8373 - val_loss: 0.3313 - val_accuracy: 0.8455\n",
      "Epoch 24/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3480 - accuracy: 0.8340 - val_loss: 0.3312 - val_accuracy: 0.8443\n",
      "Epoch 25/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3495 - accuracy: 0.8398 - val_loss: 0.3320 - val_accuracy: 0.8485\n",
      "Epoch 26/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3527 - accuracy: 0.8334 - val_loss: 0.3316 - val_accuracy: 0.8479\n",
      "Epoch 27/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3498 - accuracy: 0.8381 - val_loss: 0.3309 - val_accuracy: 0.8467\n",
      "Epoch 28/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3515 - accuracy: 0.8357 - val_loss: 0.3303 - val_accuracy: 0.8455\n",
      "Epoch 29/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3498 - accuracy: 0.8378 - val_loss: 0.3304 - val_accuracy: 0.8443\n",
      "Epoch 30/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3539 - accuracy: 0.8343 - val_loss: 0.3305 - val_accuracy: 0.8449\n",
      "Epoch 31/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3511 - accuracy: 0.8386 - val_loss: 0.3333 - val_accuracy: 0.8485\n",
      "Epoch 32/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3541 - accuracy: 0.8334 - val_loss: 0.3339 - val_accuracy: 0.8479\n",
      "Epoch 33/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3510 - accuracy: 0.8361 - val_loss: 0.3322 - val_accuracy: 0.8467\n",
      "Epoch 34/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3490 - accuracy: 0.8375 - val_loss: 0.3312 - val_accuracy: 0.8473\n",
      "Epoch 35/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3489 - accuracy: 0.8378 - val_loss: 0.3311 - val_accuracy: 0.8418\n",
      "Epoch 36/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3467 - accuracy: 0.8334 - val_loss: 0.3306 - val_accuracy: 0.8449\n",
      "Epoch 37/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3500 - accuracy: 0.8367 - val_loss: 0.3306 - val_accuracy: 0.8461\n",
      "Epoch 38/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3475 - accuracy: 0.8379 - val_loss: 0.3300 - val_accuracy: 0.8455\n",
      "Epoch 39/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3472 - accuracy: 0.8348 - val_loss: 0.3298 - val_accuracy: 0.8455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3481 - accuracy: 0.8389 - val_loss: 0.3298 - val_accuracy: 0.8455\n",
      "Epoch 41/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3476 - accuracy: 0.8367 - val_loss: 0.3299 - val_accuracy: 0.8461\n",
      "Epoch 42/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3488 - accuracy: 0.8393 - val_loss: 0.3299 - val_accuracy: 0.8461\n",
      "Epoch 43/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3503 - accuracy: 0.8349 - val_loss: 0.3323 - val_accuracy: 0.8388\n",
      "Epoch 44/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3485 - accuracy: 0.8360 - val_loss: 0.3323 - val_accuracy: 0.8400\n",
      "Epoch 45/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3440 - accuracy: 0.8398 - val_loss: 0.3321 - val_accuracy: 0.8412\n",
      "Epoch 46/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3512 - accuracy: 0.8376 - val_loss: 0.3319 - val_accuracy: 0.8418\n",
      "Epoch 47/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3472 - accuracy: 0.8392 - val_loss: 0.3318 - val_accuracy: 0.8425\n",
      "Epoch 48/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3413 - accuracy: 0.8364 - val_loss: 0.3314 - val_accuracy: 0.8412\n",
      "Epoch 49/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3467 - accuracy: 0.8363 - val_loss: 0.3311 - val_accuracy: 0.8443\n",
      "Epoch 50/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3481 - accuracy: 0.8389 - val_loss: 0.3312 - val_accuracy: 0.8461\n",
      "Epoch 51/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3467 - accuracy: 0.8396 - val_loss: 0.3311 - val_accuracy: 0.8449\n",
      "Epoch 52/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3485 - accuracy: 0.8351 - val_loss: 0.3317 - val_accuracy: 0.8418\n",
      "Epoch 53/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3462 - accuracy: 0.8351 - val_loss: 0.3319 - val_accuracy: 0.8418\n",
      "Epoch 54/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3512 - accuracy: 0.8364 - val_loss: 0.3322 - val_accuracy: 0.8412\n",
      "Epoch 55/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3454 - accuracy: 0.8387 - val_loss: 0.3333 - val_accuracy: 0.8437\n",
      "Epoch 56/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3499 - accuracy: 0.8361 - val_loss: 0.3338 - val_accuracy: 0.8455\n",
      "Epoch 57/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3509 - accuracy: 0.8351 - val_loss: 0.3340 - val_accuracy: 0.8449\n",
      "Epoch 58/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3457 - accuracy: 0.8378 - val_loss: 0.3329 - val_accuracy: 0.8443\n",
      "Epoch 59/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3444 - accuracy: 0.8384 - val_loss: 0.3324 - val_accuracy: 0.8449\n",
      "Epoch 60/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3439 - accuracy: 0.8399 - val_loss: 0.3329 - val_accuracy: 0.8449\n",
      "Epoch 61/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3464 - accuracy: 0.8386 - val_loss: 0.3338 - val_accuracy: 0.8443\n",
      "Epoch 62/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3503 - accuracy: 0.8337 - val_loss: 0.3343 - val_accuracy: 0.8498\n",
      "Epoch 63/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3483 - accuracy: 0.8343 - val_loss: 0.3334 - val_accuracy: 0.8485\n",
      "Epoch 64/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3495 - accuracy: 0.8346 - val_loss: 0.3329 - val_accuracy: 0.8485\n",
      "Epoch 65/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3446 - accuracy: 0.8398 - val_loss: 0.3324 - val_accuracy: 0.8491\n",
      "Epoch 66/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3454 - accuracy: 0.8376 - val_loss: 0.3320 - val_accuracy: 0.8485\n",
      "Epoch 67/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3457 - accuracy: 0.8367 - val_loss: 0.3321 - val_accuracy: 0.8479\n",
      "Epoch 68/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3451 - accuracy: 0.8364 - val_loss: 0.3315 - val_accuracy: 0.8461\n",
      "Epoch 69/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3512 - accuracy: 0.8366 - val_loss: 0.3318 - val_accuracy: 0.8412\n",
      "Epoch 70/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.3457 - accuracy: 0.8346 - val_loss: 0.3316 - val_accuracy: 0.8406\n",
      "Epoch 71/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3435 - accuracy: 0.8348 - val_loss: 0.3306 - val_accuracy: 0.8437\n",
      "Epoch 72/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3441 - accuracy: 0.8372 - val_loss: 0.3305 - val_accuracy: 0.8418\n",
      "Epoch 73/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3475 - accuracy: 0.8372 - val_loss: 0.3314 - val_accuracy: 0.8382\n",
      "Epoch 74/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3472 - accuracy: 0.8389 - val_loss: 0.3304 - val_accuracy: 0.8388\n",
      "Epoch 75/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3429 - accuracy: 0.8418 - val_loss: 0.3302 - val_accuracy: 0.8370\n",
      "Epoch 76/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3471 - accuracy: 0.8384 - val_loss: 0.3300 - val_accuracy: 0.8400\n",
      "Epoch 77/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3489 - accuracy: 0.8335 - val_loss: 0.3295 - val_accuracy: 0.8412\n",
      "Epoch 78/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.3474 - accuracy: 0.8344 - val_loss: 0.3298 - val_accuracy: 0.8425\n",
      "Epoch 79/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3489 - accuracy: 0.8373 - val_loss: 0.3297 - val_accuracy: 0.8425\n",
      "Epoch 80/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.3478 - accuracy: 0.8355 - val_loss: 0.3298 - val_accuracy: 0.8437\n",
      "Epoch 81/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3417 - accuracy: 0.8389 - val_loss: 0.3320 - val_accuracy: 0.8449\n",
      "Epoch 82/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3464 - accuracy: 0.8338 - val_loss: 0.3328 - val_accuracy: 0.8491\n",
      "Epoch 83/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3486 - accuracy: 0.8329 - val_loss: 0.3315 - val_accuracy: 0.8473\n",
      "Epoch 84/100\n",
      "6572/6572 [==============================] - 0s 14us/sample - loss: 0.3485 - accuracy: 0.8375 - val_loss: 0.3303 - val_accuracy: 0.8425\n",
      "Epoch 85/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.3481 - accuracy: 0.8349 - val_loss: 0.3317 - val_accuracy: 0.8364\n",
      "Epoch 86/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3489 - accuracy: 0.8360 - val_loss: 0.3321 - val_accuracy: 0.8382\n",
      "Epoch 87/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3485 - accuracy: 0.8340 - val_loss: 0.3321 - val_accuracy: 0.8376\n",
      "Epoch 88/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3439 - accuracy: 0.8379 - val_loss: 0.3320 - val_accuracy: 0.8376\n",
      "Epoch 89/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.3452 - accuracy: 0.8392 - val_loss: 0.3316 - val_accuracy: 0.8376\n",
      "Epoch 90/100\n",
      "6572/6572 [==============================] - 0s 15us/sample - loss: 0.3461 - accuracy: 0.8379 - val_loss: 0.3313 - val_accuracy: 0.8400\n",
      "Epoch 91/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.3445 - accuracy: 0.8408 - val_loss: 0.3316 - val_accuracy: 0.8412\n",
      "Epoch 92/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.3440 - accuracy: 0.8354 - val_loss: 0.3313 - val_accuracy: 0.8406\n",
      "Epoch 93/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3454 - accuracy: 0.8393 - val_loss: 0.3310 - val_accuracy: 0.8412\n",
      "Epoch 94/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3481 - accuracy: 0.8352 - val_loss: 0.3312 - val_accuracy: 0.8449\n",
      "Epoch 95/100\n",
      "6572/6572 [==============================] - 0s 14us/sample - loss: 0.3434 - accuracy: 0.8372 - val_loss: 0.3309 - val_accuracy: 0.8437\n",
      "Epoch 96/100\n",
      "6572/6572 [==============================] - 0s 15us/sample - loss: 0.3424 - accuracy: 0.8370 - val_loss: 0.3310 - val_accuracy: 0.8479\n",
      "Epoch 97/100\n",
      "6572/6572 [==============================] - 0s 14us/sample - loss: 0.3416 - accuracy: 0.8369 - val_loss: 0.3311 - val_accuracy: 0.8491\n",
      "Epoch 98/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.3439 - accuracy: 0.8355 - val_loss: 0.3306 - val_accuracy: 0.8485\n",
      "Epoch 99/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.3423 - accuracy: 0.8364 - val_loss: 0.3300 - val_accuracy: 0.8449\n",
      "Epoch 100/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3420 - accuracy: 0.8393 - val_loss: 0.3294 - val_accuracy: 0.8443\n",
      "Feature Space:  (6572, 9)\n",
      "Train on 6572 samples, validate on 1644 samples\n",
      "Epoch 1/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3466 - accuracy: 0.8361 - val_loss: 0.3281 - val_accuracy: 0.8431\n",
      "Epoch 2/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3401 - accuracy: 0.8402 - val_loss: 0.3285 - val_accuracy: 0.8467\n",
      "Epoch 3/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3437 - accuracy: 0.8402 - val_loss: 0.3281 - val_accuracy: 0.8461\n",
      "Epoch 4/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3424 - accuracy: 0.8376 - val_loss: 0.3277 - val_accuracy: 0.8455\n",
      "Epoch 5/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3436 - accuracy: 0.8378 - val_loss: 0.3290 - val_accuracy: 0.8485\n",
      "Epoch 6/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3414 - accuracy: 0.8332 - val_loss: 0.3303 - val_accuracy: 0.8510\n",
      "Epoch 7/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3386 - accuracy: 0.8404 - val_loss: 0.3314 - val_accuracy: 0.8485\n",
      "Epoch 8/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3480 - accuracy: 0.8323 - val_loss: 0.3347 - val_accuracy: 0.8485\n",
      "Epoch 9/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3465 - accuracy: 0.8399 - val_loss: 0.3322 - val_accuracy: 0.8485\n",
      "Epoch 10/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.3451 - accuracy: 0.8401 - val_loss: 0.3296 - val_accuracy: 0.8455\n",
      "Epoch 11/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3456 - accuracy: 0.8379 - val_loss: 0.3288 - val_accuracy: 0.8437\n",
      "Epoch 12/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3399 - accuracy: 0.8381 - val_loss: 0.3289 - val_accuracy: 0.8418\n",
      "Epoch 13/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3420 - accuracy: 0.8367 - val_loss: 0.3287 - val_accuracy: 0.8418\n",
      "Epoch 14/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3394 - accuracy: 0.8421 - val_loss: 0.3282 - val_accuracy: 0.8412\n",
      "Epoch 15/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3418 - accuracy: 0.8390 - val_loss: 0.3276 - val_accuracy: 0.8431\n",
      "Epoch 16/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3390 - accuracy: 0.8410 - val_loss: 0.3272 - val_accuracy: 0.8473\n",
      "Epoch 17/100\n",
      "6572/6572 [==============================] - 0s 14us/sample - loss: 0.3419 - accuracy: 0.8381 - val_loss: 0.3276 - val_accuracy: 0.8485\n",
      "Epoch 18/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3414 - accuracy: 0.8411 - val_loss: 0.3273 - val_accuracy: 0.8479\n",
      "Epoch 19/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3450 - accuracy: 0.8360 - val_loss: 0.3266 - val_accuracy: 0.8461\n",
      "Epoch 20/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3419 - accuracy: 0.8393 - val_loss: 0.3264 - val_accuracy: 0.8467\n",
      "Epoch 21/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3391 - accuracy: 0.8387 - val_loss: 0.3269 - val_accuracy: 0.8491\n",
      "Epoch 22/100\n",
      "6572/6572 [==============================] - 0s 16us/sample - loss: 0.3427 - accuracy: 0.8367 - val_loss: 0.3270 - val_accuracy: 0.8443\n",
      "Epoch 23/100\n",
      "6572/6572 [==============================] - 0s 22us/sample - loss: 0.3380 - accuracy: 0.8404 - val_loss: 0.3280 - val_accuracy: 0.8491\n",
      "Epoch 24/100\n",
      "6572/6572 [==============================] - 0s 17us/sample - loss: 0.3430 - accuracy: 0.8366 - val_loss: 0.3283 - val_accuracy: 0.8504\n",
      "Epoch 25/100\n",
      "6572/6572 [==============================] - 0s 17us/sample - loss: 0.3401 - accuracy: 0.8392 - val_loss: 0.3293 - val_accuracy: 0.8491\n",
      "Epoch 26/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3435 - accuracy: 0.8384 - val_loss: 0.3290 - val_accuracy: 0.8485\n",
      "Epoch 27/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3435 - accuracy: 0.8367 - val_loss: 0.3294 - val_accuracy: 0.8498\n",
      "Epoch 28/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3423 - accuracy: 0.8398 - val_loss: 0.3309 - val_accuracy: 0.8516\n",
      "Epoch 29/100\n",
      "6572/6572 [==============================] - 0s 14us/sample - loss: 0.3421 - accuracy: 0.8392 - val_loss: 0.3287 - val_accuracy: 0.8510\n",
      "Epoch 30/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3407 - accuracy: 0.8379 - val_loss: 0.3273 - val_accuracy: 0.8437\n",
      "Epoch 31/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3424 - accuracy: 0.8398 - val_loss: 0.3271 - val_accuracy: 0.8394\n",
      "Epoch 32/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3389 - accuracy: 0.8398 - val_loss: 0.3270 - val_accuracy: 0.8394\n",
      "Epoch 33/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3418 - accuracy: 0.8383 - val_loss: 0.3273 - val_accuracy: 0.8406\n",
      "Epoch 34/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3394 - accuracy: 0.8364 - val_loss: 0.3279 - val_accuracy: 0.8382\n",
      "Epoch 35/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3407 - accuracy: 0.8402 - val_loss: 0.3272 - val_accuracy: 0.8376\n",
      "Epoch 36/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.3427 - accuracy: 0.8379 - val_loss: 0.3267 - val_accuracy: 0.8388\n",
      "Epoch 37/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.3376 - accuracy: 0.8407 - val_loss: 0.3277 - val_accuracy: 0.8449\n",
      "Epoch 38/100\n",
      "6572/6572 [==============================] - 0s 13us/sample - loss: 0.3396 - accuracy: 0.8414 - val_loss: 0.3277 - val_accuracy: 0.8443\n",
      "Epoch 39/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3435 - accuracy: 0.8370 - val_loss: 0.3272 - val_accuracy: 0.8412\n",
      "Epoch 40/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3413 - accuracy: 0.8401 - val_loss: 0.3274 - val_accuracy: 0.8418\n",
      "Epoch 41/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3381 - accuracy: 0.8418 - val_loss: 0.3297 - val_accuracy: 0.8443\n",
      "Epoch 42/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3440 - accuracy: 0.8369 - val_loss: 0.3300 - val_accuracy: 0.8437\n",
      "Epoch 43/100\n",
      "6572/6572 [==============================] - 0s 12us/sample - loss: 0.3415 - accuracy: 0.8414 - val_loss: 0.3292 - val_accuracy: 0.8443\n",
      "Epoch 44/100\n",
      "6572/6572 [==============================] - 0s 11us/sample - loss: 0.3393 - accuracy: 0.8398 - val_loss: 0.3285 - val_accuracy: 0.8449\n",
      "Epoch 45/100\n",
      "6572/6572 [==============================] - 0s 8us/sample - loss: 0.3372 - accuracy: 0.8392 - val_loss: 0.3280 - val_accuracy: 0.8418\n",
      "Epoch 46/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3380 - accuracy: 0.8434 - val_loss: 0.3276 - val_accuracy: 0.8412\n",
      "Epoch 47/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3414 - accuracy: 0.8390 - val_loss: 0.3276 - val_accuracy: 0.8370\n",
      "Epoch 48/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3403 - accuracy: 0.8364 - val_loss: 0.3286 - val_accuracy: 0.8339\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3384 - accuracy: 0.8442 - val_loss: 0.3294 - val_accuracy: 0.8370\n",
      "Epoch 50/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3399 - accuracy: 0.8379 - val_loss: 0.3288 - val_accuracy: 0.8388\n",
      "Epoch 51/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3380 - accuracy: 0.8437 - val_loss: 0.3290 - val_accuracy: 0.8412\n",
      "Epoch 52/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3418 - accuracy: 0.8414 - val_loss: 0.3325 - val_accuracy: 0.8473\n",
      "Epoch 53/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3398 - accuracy: 0.8390 - val_loss: 0.3320 - val_accuracy: 0.8467\n",
      "Epoch 54/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3409 - accuracy: 0.8381 - val_loss: 0.3307 - val_accuracy: 0.8437\n",
      "Epoch 55/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3337 - accuracy: 0.8451 - val_loss: 0.3295 - val_accuracy: 0.8406\n",
      "Epoch 56/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3411 - accuracy: 0.8411 - val_loss: 0.3287 - val_accuracy: 0.8394\n",
      "Epoch 57/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3366 - accuracy: 0.8428 - val_loss: 0.3279 - val_accuracy: 0.8418\n",
      "Epoch 58/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3401 - accuracy: 0.8369 - val_loss: 0.3291 - val_accuracy: 0.8388\n",
      "Epoch 59/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3408 - accuracy: 0.8390 - val_loss: 0.3293 - val_accuracy: 0.8418\n",
      "Epoch 60/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3388 - accuracy: 0.8387 - val_loss: 0.3289 - val_accuracy: 0.8431\n",
      "Epoch 61/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3376 - accuracy: 0.8398 - val_loss: 0.3281 - val_accuracy: 0.8431\n",
      "Epoch 62/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3387 - accuracy: 0.8414 - val_loss: 0.3291 - val_accuracy: 0.8485\n",
      "Epoch 63/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3389 - accuracy: 0.8383 - val_loss: 0.3282 - val_accuracy: 0.8461\n",
      "Epoch 64/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3406 - accuracy: 0.8367 - val_loss: 0.3277 - val_accuracy: 0.8443\n",
      "Epoch 65/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3419 - accuracy: 0.8378 - val_loss: 0.3279 - val_accuracy: 0.8455\n",
      "Epoch 66/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3353 - accuracy: 0.8410 - val_loss: 0.3279 - val_accuracy: 0.8431\n",
      "Epoch 67/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3428 - accuracy: 0.8408 - val_loss: 0.3287 - val_accuracy: 0.8437\n",
      "Epoch 68/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3427 - accuracy: 0.8383 - val_loss: 0.3316 - val_accuracy: 0.8455\n",
      "Epoch 69/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3414 - accuracy: 0.8410 - val_loss: 0.3318 - val_accuracy: 0.8455\n",
      "Epoch 70/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3373 - accuracy: 0.8378 - val_loss: 0.3318 - val_accuracy: 0.8455\n",
      "Epoch 71/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3411 - accuracy: 0.8357 - val_loss: 0.3324 - val_accuracy: 0.8449\n",
      "Epoch 72/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3409 - accuracy: 0.8402 - val_loss: 0.3326 - val_accuracy: 0.8443\n",
      "Epoch 73/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3427 - accuracy: 0.8398 - val_loss: 0.3318 - val_accuracy: 0.8467\n",
      "Epoch 74/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3364 - accuracy: 0.8427 - val_loss: 0.3306 - val_accuracy: 0.8455\n",
      "Epoch 75/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3413 - accuracy: 0.8369 - val_loss: 0.3299 - val_accuracy: 0.8455\n",
      "Epoch 76/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3373 - accuracy: 0.8422 - val_loss: 0.3293 - val_accuracy: 0.8479\n",
      "Epoch 77/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3427 - accuracy: 0.8372 - val_loss: 0.3308 - val_accuracy: 0.8437\n",
      "Epoch 78/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3428 - accuracy: 0.8346 - val_loss: 0.3317 - val_accuracy: 0.8449\n",
      "Epoch 79/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3403 - accuracy: 0.8407 - val_loss: 0.3318 - val_accuracy: 0.8479\n",
      "Epoch 80/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3409 - accuracy: 0.8387 - val_loss: 0.3311 - val_accuracy: 0.8449\n",
      "Epoch 81/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3412 - accuracy: 0.8393 - val_loss: 0.3306 - val_accuracy: 0.8443\n",
      "Epoch 82/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3356 - accuracy: 0.8407 - val_loss: 0.3299 - val_accuracy: 0.8418\n",
      "Epoch 83/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3391 - accuracy: 0.8393 - val_loss: 0.3294 - val_accuracy: 0.8431\n",
      "Epoch 84/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3382 - accuracy: 0.8372 - val_loss: 0.3291 - val_accuracy: 0.8437\n",
      "Epoch 85/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3369 - accuracy: 0.8414 - val_loss: 0.3288 - val_accuracy: 0.8425\n",
      "Epoch 86/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3388 - accuracy: 0.8422 - val_loss: 0.3288 - val_accuracy: 0.8425\n",
      "Epoch 87/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3403 - accuracy: 0.8392 - val_loss: 0.3287 - val_accuracy: 0.8425\n",
      "Epoch 88/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3369 - accuracy: 0.8430 - val_loss: 0.3285 - val_accuracy: 0.8431\n",
      "Epoch 89/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3377 - accuracy: 0.8402 - val_loss: 0.3282 - val_accuracy: 0.8431\n",
      "Epoch 90/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3382 - accuracy: 0.8402 - val_loss: 0.3286 - val_accuracy: 0.8425\n",
      "Epoch 91/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3374 - accuracy: 0.8421 - val_loss: 0.3285 - val_accuracy: 0.8425\n",
      "Epoch 92/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3360 - accuracy: 0.8414 - val_loss: 0.3291 - val_accuracy: 0.8388\n",
      "Epoch 93/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3372 - accuracy: 0.8407 - val_loss: 0.3292 - val_accuracy: 0.8382\n",
      "Epoch 94/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3335 - accuracy: 0.8425 - val_loss: 0.3288 - val_accuracy: 0.8394\n",
      "Epoch 95/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3368 - accuracy: 0.8381 - val_loss: 0.3288 - val_accuracy: 0.8431\n",
      "Epoch 96/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3418 - accuracy: 0.8399 - val_loss: 0.3285 - val_accuracy: 0.8437\n",
      "Epoch 97/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3351 - accuracy: 0.8436 - val_loss: 0.3279 - val_accuracy: 0.8431\n",
      "Epoch 98/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3383 - accuracy: 0.8421 - val_loss: 0.3272 - val_accuracy: 0.8418\n",
      "Epoch 99/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3337 - accuracy: 0.8439 - val_loss: 0.3268 - val_accuracy: 0.8418\n",
      "Epoch 100/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3383 - accuracy: 0.8378 - val_loss: 0.3270 - val_accuracy: 0.8400\n",
      "Feature Space:  (6572, 9)\n",
      "Train on 6572 samples, validate on 1644 samples\n",
      "Epoch 1/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3394 - accuracy: 0.8425 - val_loss: 0.3261 - val_accuracy: 0.8498\n",
      "Epoch 2/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3354 - accuracy: 0.8431 - val_loss: 0.3268 - val_accuracy: 0.8498\n",
      "Epoch 3/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3320 - accuracy: 0.8468 - val_loss: 0.3259 - val_accuracy: 0.8504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3350 - accuracy: 0.8484 - val_loss: 0.3257 - val_accuracy: 0.8516\n",
      "Epoch 5/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3347 - accuracy: 0.8454 - val_loss: 0.3253 - val_accuracy: 0.8504\n",
      "Epoch 6/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3378 - accuracy: 0.8439 - val_loss: 0.3250 - val_accuracy: 0.8491\n",
      "Epoch 7/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3310 - accuracy: 0.8488 - val_loss: 0.3252 - val_accuracy: 0.8485\n",
      "Epoch 8/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3338 - accuracy: 0.8488 - val_loss: 0.3256 - val_accuracy: 0.8498\n",
      "Epoch 9/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3349 - accuracy: 0.8492 - val_loss: 0.3256 - val_accuracy: 0.8510\n",
      "Epoch 10/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3341 - accuracy: 0.8445 - val_loss: 0.3251 - val_accuracy: 0.8522\n",
      "Epoch 11/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3330 - accuracy: 0.8462 - val_loss: 0.3251 - val_accuracy: 0.8510\n",
      "Epoch 12/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3365 - accuracy: 0.8480 - val_loss: 0.3245 - val_accuracy: 0.8516\n",
      "Epoch 13/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3342 - accuracy: 0.8474 - val_loss: 0.3257 - val_accuracy: 0.8491\n",
      "Epoch 14/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3339 - accuracy: 0.8468 - val_loss: 0.3254 - val_accuracy: 0.8510\n",
      "Epoch 15/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3336 - accuracy: 0.8460 - val_loss: 0.3254 - val_accuracy: 0.8516\n",
      "Epoch 16/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3311 - accuracy: 0.8466 - val_loss: 0.3258 - val_accuracy: 0.8510\n",
      "Epoch 17/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3327 - accuracy: 0.8463 - val_loss: 0.3258 - val_accuracy: 0.8498\n",
      "Epoch 18/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3334 - accuracy: 0.8475 - val_loss: 0.3270 - val_accuracy: 0.8498\n",
      "Epoch 19/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3306 - accuracy: 0.8466 - val_loss: 0.3272 - val_accuracy: 0.8498\n",
      "Epoch 20/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3328 - accuracy: 0.8439 - val_loss: 0.3279 - val_accuracy: 0.8516\n",
      "Epoch 21/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3302 - accuracy: 0.8457 - val_loss: 0.3278 - val_accuracy: 0.8498\n",
      "Epoch 22/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3319 - accuracy: 0.8484 - val_loss: 0.3274 - val_accuracy: 0.8479\n",
      "Epoch 23/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3358 - accuracy: 0.8451 - val_loss: 0.3267 - val_accuracy: 0.8479\n",
      "Epoch 24/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3331 - accuracy: 0.8472 - val_loss: 0.3263 - val_accuracy: 0.8510\n",
      "Epoch 25/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3330 - accuracy: 0.8463 - val_loss: 0.3258 - val_accuracy: 0.8516\n",
      "Epoch 26/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3340 - accuracy: 0.8481 - val_loss: 0.3268 - val_accuracy: 0.8498\n",
      "Epoch 27/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3309 - accuracy: 0.8448 - val_loss: 0.3268 - val_accuracy: 0.8491\n",
      "Epoch 28/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3360 - accuracy: 0.8449 - val_loss: 0.3258 - val_accuracy: 0.8504\n",
      "Epoch 29/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3324 - accuracy: 0.8477 - val_loss: 0.3242 - val_accuracy: 0.8522\n",
      "Epoch 30/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3336 - accuracy: 0.8460 - val_loss: 0.3245 - val_accuracy: 0.8504\n",
      "Epoch 31/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3342 - accuracy: 0.8494 - val_loss: 0.3254 - val_accuracy: 0.8491\n",
      "Epoch 32/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3302 - accuracy: 0.8488 - val_loss: 0.3273 - val_accuracy: 0.8498\n",
      "Epoch 33/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3351 - accuracy: 0.8478 - val_loss: 0.3274 - val_accuracy: 0.8498\n",
      "Epoch 34/100\n",
      "6572/6572 [==============================] - 0s 8us/sample - loss: 0.3346 - accuracy: 0.8477 - val_loss: 0.3275 - val_accuracy: 0.8498\n",
      "Epoch 35/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3341 - accuracy: 0.8459 - val_loss: 0.3278 - val_accuracy: 0.8504\n",
      "Epoch 36/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3285 - accuracy: 0.8494 - val_loss: 0.3278 - val_accuracy: 0.8498\n",
      "Epoch 37/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3329 - accuracy: 0.8498 - val_loss: 0.3283 - val_accuracy: 0.8479\n",
      "Epoch 38/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3360 - accuracy: 0.8456 - val_loss: 0.3272 - val_accuracy: 0.8479\n",
      "Epoch 39/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3283 - accuracy: 0.8486 - val_loss: 0.3268 - val_accuracy: 0.8498\n",
      "Epoch 40/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3313 - accuracy: 0.8478 - val_loss: 0.3264 - val_accuracy: 0.8491\n",
      "Epoch 41/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3339 - accuracy: 0.8492 - val_loss: 0.3270 - val_accuracy: 0.8498\n",
      "Epoch 42/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3299 - accuracy: 0.8477 - val_loss: 0.3275 - val_accuracy: 0.8491\n",
      "Epoch 43/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3335 - accuracy: 0.8460 - val_loss: 0.3272 - val_accuracy: 0.8467\n",
      "Epoch 44/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3349 - accuracy: 0.8501 - val_loss: 0.3264 - val_accuracy: 0.8485\n",
      "Epoch 45/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3301 - accuracy: 0.8478 - val_loss: 0.3260 - val_accuracy: 0.8498\n",
      "Epoch 46/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3281 - accuracy: 0.8463 - val_loss: 0.3258 - val_accuracy: 0.8510\n",
      "Epoch 47/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3306 - accuracy: 0.8495 - val_loss: 0.3280 - val_accuracy: 0.8491\n",
      "Epoch 48/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3325 - accuracy: 0.8486 - val_loss: 0.3286 - val_accuracy: 0.8473\n",
      "Epoch 49/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3335 - accuracy: 0.8463 - val_loss: 0.3284 - val_accuracy: 0.8467\n",
      "Epoch 50/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3353 - accuracy: 0.8498 - val_loss: 0.3298 - val_accuracy: 0.8473\n",
      "Epoch 51/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3381 - accuracy: 0.8440 - val_loss: 0.3294 - val_accuracy: 0.8473\n",
      "Epoch 52/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3347 - accuracy: 0.8457 - val_loss: 0.3296 - val_accuracy: 0.8449\n",
      "Epoch 53/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3334 - accuracy: 0.8454 - val_loss: 0.3305 - val_accuracy: 0.8461\n",
      "Epoch 54/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3370 - accuracy: 0.8437 - val_loss: 0.3300 - val_accuracy: 0.8443\n",
      "Epoch 55/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3314 - accuracy: 0.8446 - val_loss: 0.3281 - val_accuracy: 0.8467\n",
      "Epoch 56/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3295 - accuracy: 0.8474 - val_loss: 0.3280 - val_accuracy: 0.8467\n",
      "Epoch 57/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3322 - accuracy: 0.8491 - val_loss: 0.3276 - val_accuracy: 0.8461\n",
      "Epoch 58/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3316 - accuracy: 0.8474 - val_loss: 0.3260 - val_accuracy: 0.8491\n",
      "Epoch 59/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3287 - accuracy: 0.8468 - val_loss: 0.3257 - val_accuracy: 0.8510\n",
      "Epoch 60/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3324 - accuracy: 0.8474 - val_loss: 0.3254 - val_accuracy: 0.8510\n",
      "Epoch 61/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3324 - accuracy: 0.8513 - val_loss: 0.3251 - val_accuracy: 0.8504\n",
      "Epoch 62/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3337 - accuracy: 0.8471 - val_loss: 0.3248 - val_accuracy: 0.8498\n",
      "Epoch 63/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3291 - accuracy: 0.8492 - val_loss: 0.3264 - val_accuracy: 0.8510\n",
      "Epoch 64/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3346 - accuracy: 0.8468 - val_loss: 0.3263 - val_accuracy: 0.8485\n",
      "Epoch 65/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3354 - accuracy: 0.8478 - val_loss: 0.3248 - val_accuracy: 0.8522\n",
      "Epoch 66/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3329 - accuracy: 0.8463 - val_loss: 0.3253 - val_accuracy: 0.8522\n",
      "Epoch 67/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3377 - accuracy: 0.8448 - val_loss: 0.3262 - val_accuracy: 0.8479\n",
      "Epoch 68/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3333 - accuracy: 0.8466 - val_loss: 0.3263 - val_accuracy: 0.8479\n",
      "Epoch 69/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3331 - accuracy: 0.8471 - val_loss: 0.3259 - val_accuracy: 0.8485\n",
      "Epoch 70/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3352 - accuracy: 0.8478 - val_loss: 0.3268 - val_accuracy: 0.8516\n",
      "Epoch 71/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3330 - accuracy: 0.8509 - val_loss: 0.3275 - val_accuracy: 0.8516\n",
      "Epoch 72/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3329 - accuracy: 0.8449 - val_loss: 0.3272 - val_accuracy: 0.8498\n",
      "Epoch 73/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3332 - accuracy: 0.8501 - val_loss: 0.3271 - val_accuracy: 0.8498\n",
      "Epoch 74/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3322 - accuracy: 0.8494 - val_loss: 0.3268 - val_accuracy: 0.8510\n",
      "Epoch 75/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3321 - accuracy: 0.8494 - val_loss: 0.3265 - val_accuracy: 0.8491\n",
      "Epoch 76/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3317 - accuracy: 0.8500 - val_loss: 0.3264 - val_accuracy: 0.8491\n",
      "Epoch 77/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3326 - accuracy: 0.8472 - val_loss: 0.3282 - val_accuracy: 0.8516\n",
      "Epoch 78/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3365 - accuracy: 0.8454 - val_loss: 0.3286 - val_accuracy: 0.8510\n",
      "Epoch 79/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3331 - accuracy: 0.8437 - val_loss: 0.3283 - val_accuracy: 0.8516\n",
      "Epoch 80/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3277 - accuracy: 0.8512 - val_loss: 0.3279 - val_accuracy: 0.8510\n",
      "Epoch 81/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3312 - accuracy: 0.8500 - val_loss: 0.3275 - val_accuracy: 0.8522\n",
      "Epoch 82/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3330 - accuracy: 0.8478 - val_loss: 0.3270 - val_accuracy: 0.8522\n",
      "Epoch 83/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3328 - accuracy: 0.8481 - val_loss: 0.3264 - val_accuracy: 0.8504\n",
      "Epoch 84/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3343 - accuracy: 0.8491 - val_loss: 0.3256 - val_accuracy: 0.8522\n",
      "Epoch 85/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3319 - accuracy: 0.8498 - val_loss: 0.3254 - val_accuracy: 0.8528\n",
      "Epoch 86/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3351 - accuracy: 0.8475 - val_loss: 0.3252 - val_accuracy: 0.8534\n",
      "Epoch 87/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3330 - accuracy: 0.8489 - val_loss: 0.3249 - val_accuracy: 0.8528\n",
      "Epoch 88/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3309 - accuracy: 0.8475 - val_loss: 0.3250 - val_accuracy: 0.8528\n",
      "Epoch 89/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3327 - accuracy: 0.8474 - val_loss: 0.3258 - val_accuracy: 0.8485\n",
      "Epoch 90/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3319 - accuracy: 0.8474 - val_loss: 0.3261 - val_accuracy: 0.8455\n",
      "Epoch 91/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3321 - accuracy: 0.8504 - val_loss: 0.3258 - val_accuracy: 0.8467\n",
      "Epoch 92/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3290 - accuracy: 0.8507 - val_loss: 0.3251 - val_accuracy: 0.8491\n",
      "Epoch 93/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3314 - accuracy: 0.8495 - val_loss: 0.3261 - val_accuracy: 0.8498\n",
      "Epoch 94/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3332 - accuracy: 0.8501 - val_loss: 0.3254 - val_accuracy: 0.8504\n",
      "Epoch 95/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3285 - accuracy: 0.8507 - val_loss: 0.3248 - val_accuracy: 0.8491\n",
      "Epoch 96/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3312 - accuracy: 0.8500 - val_loss: 0.3243 - val_accuracy: 0.8504\n",
      "Epoch 97/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3336 - accuracy: 0.8477 - val_loss: 0.3254 - val_accuracy: 0.8504\n",
      "Epoch 98/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3285 - accuracy: 0.8509 - val_loss: 0.3274 - val_accuracy: 0.8498\n",
      "Epoch 99/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3318 - accuracy: 0.8465 - val_loss: 0.3285 - val_accuracy: 0.8485\n",
      "Epoch 100/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3308 - accuracy: 0.8446 - val_loss: 0.3290 - val_accuracy: 0.8485\n",
      "Feature Space:  (6572, 9)\n",
      "Train on 6572 samples, validate on 1644 samples\n",
      "Epoch 1/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3417 - accuracy: 0.8384 - val_loss: 0.3230 - val_accuracy: 0.8485\n",
      "Epoch 2/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3356 - accuracy: 0.8407 - val_loss: 0.3233 - val_accuracy: 0.8455\n",
      "Epoch 3/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3376 - accuracy: 0.8402 - val_loss: 0.3232 - val_accuracy: 0.8467\n",
      "Epoch 4/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3371 - accuracy: 0.8399 - val_loss: 0.3219 - val_accuracy: 0.8461\n",
      "Epoch 5/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3360 - accuracy: 0.8416 - val_loss: 0.3209 - val_accuracy: 0.8467\n",
      "Epoch 6/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3359 - accuracy: 0.8408 - val_loss: 0.3203 - val_accuracy: 0.8467\n",
      "Epoch 7/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3360 - accuracy: 0.8399 - val_loss: 0.3192 - val_accuracy: 0.8449\n",
      "Epoch 8/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3356 - accuracy: 0.8390 - val_loss: 0.3199 - val_accuracy: 0.8473\n",
      "Epoch 9/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3359 - accuracy: 0.8405 - val_loss: 0.3211 - val_accuracy: 0.8443\n",
      "Epoch 10/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3363 - accuracy: 0.8399 - val_loss: 0.3207 - val_accuracy: 0.8467\n",
      "Epoch 11/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3387 - accuracy: 0.8396 - val_loss: 0.3197 - val_accuracy: 0.8455\n",
      "Epoch 12/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3410 - accuracy: 0.8389 - val_loss: 0.3193 - val_accuracy: 0.8449\n",
      "Epoch 13/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3300 - accuracy: 0.8457 - val_loss: 0.3196 - val_accuracy: 0.8449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3368 - accuracy: 0.8387 - val_loss: 0.3208 - val_accuracy: 0.8449\n",
      "Epoch 15/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3367 - accuracy: 0.8443 - val_loss: 0.3209 - val_accuracy: 0.8449\n",
      "Epoch 16/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3327 - accuracy: 0.8421 - val_loss: 0.3201 - val_accuracy: 0.8455\n",
      "Epoch 17/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3372 - accuracy: 0.8408 - val_loss: 0.3199 - val_accuracy: 0.8437\n",
      "Epoch 18/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3339 - accuracy: 0.8436 - val_loss: 0.3199 - val_accuracy: 0.8437\n",
      "Epoch 19/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3342 - accuracy: 0.8411 - val_loss: 0.3204 - val_accuracy: 0.8425\n",
      "Epoch 20/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3366 - accuracy: 0.8402 - val_loss: 0.3211 - val_accuracy: 0.8412\n",
      "Epoch 21/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3379 - accuracy: 0.8413 - val_loss: 0.3211 - val_accuracy: 0.8418\n",
      "Epoch 22/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3397 - accuracy: 0.8369 - val_loss: 0.3201 - val_accuracy: 0.8437\n",
      "Epoch 23/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3388 - accuracy: 0.8414 - val_loss: 0.3197 - val_accuracy: 0.8461\n",
      "Epoch 24/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3378 - accuracy: 0.8427 - val_loss: 0.3195 - val_accuracy: 0.8437\n",
      "Epoch 25/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3382 - accuracy: 0.8398 - val_loss: 0.3189 - val_accuracy: 0.8443\n",
      "Epoch 26/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3352 - accuracy: 0.8422 - val_loss: 0.3189 - val_accuracy: 0.8461\n",
      "Epoch 27/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3358 - accuracy: 0.8428 - val_loss: 0.3190 - val_accuracy: 0.8455\n",
      "Epoch 28/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3350 - accuracy: 0.8393 - val_loss: 0.3191 - val_accuracy: 0.8437\n",
      "Epoch 29/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3373 - accuracy: 0.8422 - val_loss: 0.3198 - val_accuracy: 0.8418\n",
      "Epoch 30/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3353 - accuracy: 0.8392 - val_loss: 0.3209 - val_accuracy: 0.8400\n",
      "Epoch 31/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3345 - accuracy: 0.8411 - val_loss: 0.3207 - val_accuracy: 0.8388\n",
      "Epoch 32/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3356 - accuracy: 0.8425 - val_loss: 0.3203 - val_accuracy: 0.8425\n",
      "Epoch 33/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3353 - accuracy: 0.8431 - val_loss: 0.3203 - val_accuracy: 0.8418\n",
      "Epoch 34/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3369 - accuracy: 0.8413 - val_loss: 0.3210 - val_accuracy: 0.8418\n",
      "Epoch 35/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3348 - accuracy: 0.8407 - val_loss: 0.3215 - val_accuracy: 0.8412\n",
      "Epoch 36/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3374 - accuracy: 0.8396 - val_loss: 0.3208 - val_accuracy: 0.8418\n",
      "Epoch 37/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3360 - accuracy: 0.8390 - val_loss: 0.3202 - val_accuracy: 0.8431\n",
      "Epoch 38/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3363 - accuracy: 0.8439 - val_loss: 0.3198 - val_accuracy: 0.8418\n",
      "Epoch 39/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3336 - accuracy: 0.8454 - val_loss: 0.3193 - val_accuracy: 0.8455\n",
      "Epoch 40/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3377 - accuracy: 0.8425 - val_loss: 0.3190 - val_accuracy: 0.8449\n",
      "Epoch 41/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3353 - accuracy: 0.8408 - val_loss: 0.3186 - val_accuracy: 0.8455\n",
      "Epoch 42/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3358 - accuracy: 0.8407 - val_loss: 0.3186 - val_accuracy: 0.8455\n",
      "Epoch 43/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3351 - accuracy: 0.8402 - val_loss: 0.3200 - val_accuracy: 0.8443\n",
      "Epoch 44/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3352 - accuracy: 0.8410 - val_loss: 0.3203 - val_accuracy: 0.8431\n",
      "Epoch 45/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3357 - accuracy: 0.8431 - val_loss: 0.3200 - val_accuracy: 0.8418\n",
      "Epoch 46/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3327 - accuracy: 0.8419 - val_loss: 0.3197 - val_accuracy: 0.8412\n",
      "Epoch 47/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3306 - accuracy: 0.8437 - val_loss: 0.3195 - val_accuracy: 0.8412\n",
      "Epoch 48/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3315 - accuracy: 0.8431 - val_loss: 0.3200 - val_accuracy: 0.8418\n",
      "Epoch 49/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3311 - accuracy: 0.8418 - val_loss: 0.3200 - val_accuracy: 0.8418\n",
      "Epoch 50/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3335 - accuracy: 0.8434 - val_loss: 0.3189 - val_accuracy: 0.8418\n",
      "Epoch 51/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3350 - accuracy: 0.8414 - val_loss: 0.3200 - val_accuracy: 0.8431\n",
      "Epoch 52/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3376 - accuracy: 0.8408 - val_loss: 0.3203 - val_accuracy: 0.8425\n",
      "Epoch 53/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3328 - accuracy: 0.8427 - val_loss: 0.3201 - val_accuracy: 0.8437\n",
      "Epoch 54/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3369 - accuracy: 0.8418 - val_loss: 0.3194 - val_accuracy: 0.8449\n",
      "Epoch 55/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3386 - accuracy: 0.8395 - val_loss: 0.3196 - val_accuracy: 0.8449\n",
      "Epoch 56/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3336 - accuracy: 0.8454 - val_loss: 0.3192 - val_accuracy: 0.8437\n",
      "Epoch 57/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3327 - accuracy: 0.8462 - val_loss: 0.3194 - val_accuracy: 0.8412\n",
      "Epoch 58/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3354 - accuracy: 0.8411 - val_loss: 0.3198 - val_accuracy: 0.8412\n",
      "Epoch 59/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3358 - accuracy: 0.8390 - val_loss: 0.3250 - val_accuracy: 0.8382\n",
      "Epoch 60/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3425 - accuracy: 0.8364 - val_loss: 0.3256 - val_accuracy: 0.8333\n",
      "Epoch 61/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3356 - accuracy: 0.8352 - val_loss: 0.3252 - val_accuracy: 0.8345\n",
      "Epoch 62/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3364 - accuracy: 0.8402 - val_loss: 0.3241 - val_accuracy: 0.8400\n",
      "Epoch 63/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3354 - accuracy: 0.8428 - val_loss: 0.3242 - val_accuracy: 0.8437\n",
      "Epoch 64/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3362 - accuracy: 0.8424 - val_loss: 0.3241 - val_accuracy: 0.8406\n",
      "Epoch 65/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3373 - accuracy: 0.8379 - val_loss: 0.3236 - val_accuracy: 0.8394\n",
      "Epoch 66/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3359 - accuracy: 0.8413 - val_loss: 0.3237 - val_accuracy: 0.8394\n",
      "Epoch 67/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3340 - accuracy: 0.8414 - val_loss: 0.3232 - val_accuracy: 0.8382\n",
      "Epoch 68/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3322 - accuracy: 0.8449 - val_loss: 0.3227 - val_accuracy: 0.8394\n",
      "Epoch 69/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3373 - accuracy: 0.8422 - val_loss: 0.3233 - val_accuracy: 0.8388\n",
      "Epoch 70/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3326 - accuracy: 0.8390 - val_loss: 0.3228 - val_accuracy: 0.8345\n",
      "Epoch 71/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3362 - accuracy: 0.8392 - val_loss: 0.3223 - val_accuracy: 0.8345\n",
      "Epoch 72/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3317 - accuracy: 0.8446 - val_loss: 0.3223 - val_accuracy: 0.8400\n",
      "Epoch 73/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3340 - accuracy: 0.8401 - val_loss: 0.3222 - val_accuracy: 0.8406\n",
      "Epoch 74/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3310 - accuracy: 0.8460 - val_loss: 0.3217 - val_accuracy: 0.8400\n",
      "Epoch 75/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3386 - accuracy: 0.8419 - val_loss: 0.3209 - val_accuracy: 0.8358\n",
      "Epoch 76/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3314 - accuracy: 0.8446 - val_loss: 0.3206 - val_accuracy: 0.8358\n",
      "Epoch 77/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3349 - accuracy: 0.8390 - val_loss: 0.3205 - val_accuracy: 0.8345\n",
      "Epoch 78/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3353 - accuracy: 0.8448 - val_loss: 0.3206 - val_accuracy: 0.8364\n",
      "Epoch 79/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3340 - accuracy: 0.8418 - val_loss: 0.3231 - val_accuracy: 0.8388\n",
      "Epoch 80/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3340 - accuracy: 0.8436 - val_loss: 0.3231 - val_accuracy: 0.8382\n",
      "Epoch 81/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3373 - accuracy: 0.8407 - val_loss: 0.3251 - val_accuracy: 0.8370\n",
      "Epoch 82/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3383 - accuracy: 0.8355 - val_loss: 0.3217 - val_accuracy: 0.8382\n",
      "Epoch 83/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3343 - accuracy: 0.8401 - val_loss: 0.3209 - val_accuracy: 0.8418\n",
      "Epoch 84/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3317 - accuracy: 0.8433 - val_loss: 0.3207 - val_accuracy: 0.8412\n",
      "Epoch 85/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3330 - accuracy: 0.8437 - val_loss: 0.3215 - val_accuracy: 0.8376\n",
      "Epoch 86/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3313 - accuracy: 0.8448 - val_loss: 0.3231 - val_accuracy: 0.8388\n",
      "Epoch 87/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3344 - accuracy: 0.8410 - val_loss: 0.3240 - val_accuracy: 0.8388\n",
      "Epoch 88/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3341 - accuracy: 0.8427 - val_loss: 0.3236 - val_accuracy: 0.8400\n",
      "Epoch 89/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3361 - accuracy: 0.8398 - val_loss: 0.3233 - val_accuracy: 0.8406\n",
      "Epoch 90/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3366 - accuracy: 0.8421 - val_loss: 0.3231 - val_accuracy: 0.8418\n",
      "Epoch 91/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3329 - accuracy: 0.8431 - val_loss: 0.3228 - val_accuracy: 0.8437\n",
      "Epoch 92/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3301 - accuracy: 0.8440 - val_loss: 0.3225 - val_accuracy: 0.8461\n",
      "Epoch 93/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3304 - accuracy: 0.8456 - val_loss: 0.3219 - val_accuracy: 0.8425\n",
      "Epoch 94/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3354 - accuracy: 0.8446 - val_loss: 0.3215 - val_accuracy: 0.8437\n",
      "Epoch 95/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3291 - accuracy: 0.8478 - val_loss: 0.3213 - val_accuracy: 0.8418\n",
      "Epoch 96/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3302 - accuracy: 0.8433 - val_loss: 0.3220 - val_accuracy: 0.8406\n",
      "Epoch 97/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3332 - accuracy: 0.8443 - val_loss: 0.3221 - val_accuracy: 0.8406\n",
      "Epoch 98/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3331 - accuracy: 0.8434 - val_loss: 0.3224 - val_accuracy: 0.8400\n",
      "Epoch 99/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3296 - accuracy: 0.8446 - val_loss: 0.3230 - val_accuracy: 0.8394\n",
      "Epoch 100/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3335 - accuracy: 0.8411 - val_loss: 0.3237 - val_accuracy: 0.8394\n",
      "Feature Space:  (6572, 9)\n",
      "Train on 6572 samples, validate on 1644 samples\n",
      "Epoch 1/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3305 - accuracy: 0.8500 - val_loss: 0.3220 - val_accuracy: 0.8522\n",
      "Epoch 2/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3300 - accuracy: 0.8509 - val_loss: 0.3201 - val_accuracy: 0.8564\n",
      "Epoch 3/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3268 - accuracy: 0.8456 - val_loss: 0.3198 - val_accuracy: 0.8583\n",
      "Epoch 4/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3317 - accuracy: 0.8477 - val_loss: 0.3198 - val_accuracy: 0.8595\n",
      "Epoch 5/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3318 - accuracy: 0.8472 - val_loss: 0.3217 - val_accuracy: 0.8577\n",
      "Epoch 6/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3305 - accuracy: 0.8492 - val_loss: 0.3214 - val_accuracy: 0.8577\n",
      "Epoch 7/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3257 - accuracy: 0.8480 - val_loss: 0.3206 - val_accuracy: 0.8571\n",
      "Epoch 8/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3320 - accuracy: 0.8469 - val_loss: 0.3203 - val_accuracy: 0.8564\n",
      "Epoch 9/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3245 - accuracy: 0.8523 - val_loss: 0.3203 - val_accuracy: 0.8528\n",
      "Epoch 10/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3302 - accuracy: 0.8501 - val_loss: 0.3198 - val_accuracy: 0.8522\n",
      "Epoch 11/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3295 - accuracy: 0.8495 - val_loss: 0.3183 - val_accuracy: 0.8583\n",
      "Epoch 12/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3259 - accuracy: 0.8513 - val_loss: 0.3177 - val_accuracy: 0.8571\n",
      "Epoch 13/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3291 - accuracy: 0.8466 - val_loss: 0.3176 - val_accuracy: 0.8571\n",
      "Epoch 14/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3310 - accuracy: 0.8483 - val_loss: 0.3176 - val_accuracy: 0.8558\n",
      "Epoch 15/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3244 - accuracy: 0.8513 - val_loss: 0.3175 - val_accuracy: 0.8571\n",
      "Epoch 16/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3268 - accuracy: 0.8512 - val_loss: 0.3180 - val_accuracy: 0.8558\n",
      "Epoch 17/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3274 - accuracy: 0.8489 - val_loss: 0.3231 - val_accuracy: 0.8504\n",
      "Epoch 18/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3292 - accuracy: 0.8507 - val_loss: 0.3226 - val_accuracy: 0.8510\n",
      "Epoch 19/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3326 - accuracy: 0.8506 - val_loss: 0.3206 - val_accuracy: 0.8516\n",
      "Epoch 20/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3303 - accuracy: 0.8492 - val_loss: 0.3195 - val_accuracy: 0.8540\n",
      "Epoch 21/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3263 - accuracy: 0.8512 - val_loss: 0.3212 - val_accuracy: 0.8485\n",
      "Epoch 22/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3297 - accuracy: 0.8491 - val_loss: 0.3211 - val_accuracy: 0.8485\n",
      "Epoch 23/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3265 - accuracy: 0.8518 - val_loss: 0.3195 - val_accuracy: 0.8516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "6572/6572 [==============================] - 0s 8us/sample - loss: 0.3250 - accuracy: 0.8507 - val_loss: 0.3186 - val_accuracy: 0.8534\n",
      "Epoch 25/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3276 - accuracy: 0.8491 - val_loss: 0.3185 - val_accuracy: 0.8546\n",
      "Epoch 26/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3278 - accuracy: 0.8484 - val_loss: 0.3200 - val_accuracy: 0.8510\n",
      "Epoch 27/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3267 - accuracy: 0.8491 - val_loss: 0.3201 - val_accuracy: 0.8516\n",
      "Epoch 28/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3284 - accuracy: 0.8513 - val_loss: 0.3190 - val_accuracy: 0.8558\n",
      "Epoch 29/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3278 - accuracy: 0.8527 - val_loss: 0.3183 - val_accuracy: 0.8564\n",
      "Epoch 30/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3278 - accuracy: 0.8492 - val_loss: 0.3183 - val_accuracy: 0.8564\n",
      "Epoch 31/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3263 - accuracy: 0.8527 - val_loss: 0.3187 - val_accuracy: 0.8546\n",
      "Epoch 32/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3280 - accuracy: 0.8484 - val_loss: 0.3181 - val_accuracy: 0.8552\n",
      "Epoch 33/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3295 - accuracy: 0.8494 - val_loss: 0.3178 - val_accuracy: 0.8564\n",
      "Epoch 34/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3235 - accuracy: 0.8529 - val_loss: 0.3175 - val_accuracy: 0.8577\n",
      "Epoch 35/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3220 - accuracy: 0.8542 - val_loss: 0.3173 - val_accuracy: 0.8577\n",
      "Epoch 36/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3265 - accuracy: 0.8500 - val_loss: 0.3171 - val_accuracy: 0.8564\n",
      "Epoch 37/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3291 - accuracy: 0.8497 - val_loss: 0.3171 - val_accuracy: 0.8583\n",
      "Epoch 38/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3275 - accuracy: 0.8494 - val_loss: 0.3183 - val_accuracy: 0.8534\n",
      "Epoch 39/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3220 - accuracy: 0.8532 - val_loss: 0.3180 - val_accuracy: 0.8540\n",
      "Epoch 40/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3254 - accuracy: 0.8489 - val_loss: 0.3195 - val_accuracy: 0.8540\n",
      "Epoch 41/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3288 - accuracy: 0.8523 - val_loss: 0.3196 - val_accuracy: 0.8540\n",
      "Epoch 42/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3319 - accuracy: 0.8474 - val_loss: 0.3183 - val_accuracy: 0.8571\n",
      "Epoch 43/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3274 - accuracy: 0.8512 - val_loss: 0.3191 - val_accuracy: 0.8540\n",
      "Epoch 44/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3259 - accuracy: 0.8523 - val_loss: 0.3188 - val_accuracy: 0.8577\n",
      "Epoch 45/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3267 - accuracy: 0.8503 - val_loss: 0.3176 - val_accuracy: 0.8558\n",
      "Epoch 46/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3312 - accuracy: 0.8510 - val_loss: 0.3172 - val_accuracy: 0.8558\n",
      "Epoch 47/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3260 - accuracy: 0.8527 - val_loss: 0.3176 - val_accuracy: 0.8577\n",
      "Epoch 48/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3286 - accuracy: 0.8494 - val_loss: 0.3184 - val_accuracy: 0.8558\n",
      "Epoch 49/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3284 - accuracy: 0.8481 - val_loss: 0.3180 - val_accuracy: 0.8571\n",
      "Epoch 50/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3283 - accuracy: 0.8463 - val_loss: 0.3172 - val_accuracy: 0.8601\n",
      "Epoch 51/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3265 - accuracy: 0.8532 - val_loss: 0.3177 - val_accuracy: 0.8564\n",
      "Epoch 52/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3279 - accuracy: 0.8484 - val_loss: 0.3173 - val_accuracy: 0.8595\n",
      "Epoch 53/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3253 - accuracy: 0.8498 - val_loss: 0.3170 - val_accuracy: 0.8613\n",
      "Epoch 54/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3260 - accuracy: 0.8494 - val_loss: 0.3171 - val_accuracy: 0.8595\n",
      "Epoch 55/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3268 - accuracy: 0.8532 - val_loss: 0.3173 - val_accuracy: 0.8583\n",
      "Epoch 56/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3261 - accuracy: 0.8512 - val_loss: 0.3172 - val_accuracy: 0.8571\n",
      "Epoch 57/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3279 - accuracy: 0.8532 - val_loss: 0.3173 - val_accuracy: 0.8571\n",
      "Epoch 58/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3273 - accuracy: 0.8500 - val_loss: 0.3171 - val_accuracy: 0.8571\n",
      "Epoch 59/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3260 - accuracy: 0.8519 - val_loss: 0.3170 - val_accuracy: 0.8577\n",
      "Epoch 60/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3255 - accuracy: 0.8547 - val_loss: 0.3178 - val_accuracy: 0.8546\n",
      "Epoch 61/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3240 - accuracy: 0.8504 - val_loss: 0.3166 - val_accuracy: 0.8589\n",
      "Epoch 62/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3270 - accuracy: 0.8539 - val_loss: 0.3162 - val_accuracy: 0.8601\n",
      "Epoch 63/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3215 - accuracy: 0.8544 - val_loss: 0.3161 - val_accuracy: 0.8583\n",
      "Epoch 64/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3261 - accuracy: 0.8568 - val_loss: 0.3160 - val_accuracy: 0.8589\n",
      "Epoch 65/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3232 - accuracy: 0.8526 - val_loss: 0.3161 - val_accuracy: 0.8607\n",
      "Epoch 66/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3233 - accuracy: 0.8526 - val_loss: 0.3175 - val_accuracy: 0.8564\n",
      "Epoch 67/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3260 - accuracy: 0.8495 - val_loss: 0.3208 - val_accuracy: 0.8528\n",
      "Epoch 68/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3293 - accuracy: 0.8497 - val_loss: 0.3222 - val_accuracy: 0.8522\n",
      "Epoch 69/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3306 - accuracy: 0.8492 - val_loss: 0.3203 - val_accuracy: 0.8540\n",
      "Epoch 70/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3267 - accuracy: 0.8491 - val_loss: 0.3187 - val_accuracy: 0.8552\n",
      "Epoch 71/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3269 - accuracy: 0.8512 - val_loss: 0.3172 - val_accuracy: 0.8577\n",
      "Epoch 72/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3273 - accuracy: 0.8501 - val_loss: 0.3170 - val_accuracy: 0.8583\n",
      "Epoch 73/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3232 - accuracy: 0.8542 - val_loss: 0.3171 - val_accuracy: 0.8571\n",
      "Epoch 74/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3248 - accuracy: 0.8509 - val_loss: 0.3179 - val_accuracy: 0.8546\n",
      "Epoch 75/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3240 - accuracy: 0.8515 - val_loss: 0.3178 - val_accuracy: 0.8546\n",
      "Epoch 76/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3227 - accuracy: 0.8527 - val_loss: 0.3183 - val_accuracy: 0.8540\n",
      "Epoch 77/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3286 - accuracy: 0.8529 - val_loss: 0.3187 - val_accuracy: 0.8540\n",
      "Epoch 78/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3222 - accuracy: 0.8545 - val_loss: 0.3196 - val_accuracy: 0.8564\n",
      "Epoch 79/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3289 - accuracy: 0.8507 - val_loss: 0.3201 - val_accuracy: 0.8558\n",
      "Epoch 80/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3204 - accuracy: 0.8504 - val_loss: 0.3193 - val_accuracy: 0.8552\n",
      "Epoch 81/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3237 - accuracy: 0.8541 - val_loss: 0.3193 - val_accuracy: 0.8552\n",
      "Epoch 82/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3271 - accuracy: 0.8529 - val_loss: 0.3178 - val_accuracy: 0.8571\n",
      "Epoch 83/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3246 - accuracy: 0.8515 - val_loss: 0.3180 - val_accuracy: 0.8571\n",
      "Epoch 84/100\n",
      "6572/6572 [==============================] - 0s 8us/sample - loss: 0.3245 - accuracy: 0.8510 - val_loss: 0.3177 - val_accuracy: 0.8558\n",
      "Epoch 85/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3268 - accuracy: 0.8516 - val_loss: 0.3183 - val_accuracy: 0.8564\n",
      "Epoch 86/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3273 - accuracy: 0.8539 - val_loss: 0.3195 - val_accuracy: 0.8540\n",
      "Epoch 87/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3252 - accuracy: 0.8519 - val_loss: 0.3183 - val_accuracy: 0.8552\n",
      "Epoch 88/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3242 - accuracy: 0.8515 - val_loss: 0.3182 - val_accuracy: 0.8571\n",
      "Epoch 89/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3212 - accuracy: 0.8529 - val_loss: 0.3177 - val_accuracy: 0.8558\n",
      "Epoch 90/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3259 - accuracy: 0.8492 - val_loss: 0.3176 - val_accuracy: 0.8564\n",
      "Epoch 91/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3272 - accuracy: 0.8500 - val_loss: 0.3182 - val_accuracy: 0.8558\n",
      "Epoch 92/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3296 - accuracy: 0.8483 - val_loss: 0.3181 - val_accuracy: 0.8558\n",
      "Epoch 93/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3276 - accuracy: 0.8495 - val_loss: 0.3198 - val_accuracy: 0.8528\n",
      "Epoch 94/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3263 - accuracy: 0.8523 - val_loss: 0.3202 - val_accuracy: 0.8498\n",
      "Epoch 95/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3268 - accuracy: 0.8509 - val_loss: 0.3184 - val_accuracy: 0.8528\n",
      "Epoch 96/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3276 - accuracy: 0.8519 - val_loss: 0.3178 - val_accuracy: 0.8546\n",
      "Epoch 97/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3284 - accuracy: 0.8516 - val_loss: 0.3177 - val_accuracy: 0.8571\n",
      "Epoch 98/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3308 - accuracy: 0.8463 - val_loss: 0.3183 - val_accuracy: 0.8577\n",
      "Epoch 99/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3288 - accuracy: 0.8516 - val_loss: 0.3166 - val_accuracy: 0.8571\n",
      "Epoch 100/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3289 - accuracy: 0.8494 - val_loss: 0.3165 - val_accuracy: 0.8571\n",
      "Feature Space:  (6572, 9)\n",
      "Train on 6572 samples, validate on 1644 samples\n",
      "Epoch 1/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3350 - accuracy: 0.8481 - val_loss: 0.3273 - val_accuracy: 0.8467\n",
      "Epoch 2/100\n",
      "6572/6572 [==============================] - 0s 8us/sample - loss: 0.3366 - accuracy: 0.8454 - val_loss: 0.3267 - val_accuracy: 0.8479\n",
      "Epoch 3/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3373 - accuracy: 0.8466 - val_loss: 0.3269 - val_accuracy: 0.8473\n",
      "Epoch 4/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3308 - accuracy: 0.8463 - val_loss: 0.3275 - val_accuracy: 0.8467\n",
      "Epoch 5/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3349 - accuracy: 0.8460 - val_loss: 0.3274 - val_accuracy: 0.8449\n",
      "Epoch 6/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3344 - accuracy: 0.8451 - val_loss: 0.3269 - val_accuracy: 0.8449\n",
      "Epoch 7/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3339 - accuracy: 0.8434 - val_loss: 0.3269 - val_accuracy: 0.8437\n",
      "Epoch 8/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3332 - accuracy: 0.8454 - val_loss: 0.3281 - val_accuracy: 0.8449\n",
      "Epoch 9/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3316 - accuracy: 0.8454 - val_loss: 0.3283 - val_accuracy: 0.8437\n",
      "Epoch 10/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3311 - accuracy: 0.8453 - val_loss: 0.3288 - val_accuracy: 0.8431\n",
      "Epoch 11/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3373 - accuracy: 0.8451 - val_loss: 0.3314 - val_accuracy: 0.8406\n",
      "Epoch 12/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3369 - accuracy: 0.8469 - val_loss: 0.3330 - val_accuracy: 0.8412\n",
      "Epoch 13/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3299 - accuracy: 0.8488 - val_loss: 0.3328 - val_accuracy: 0.8406\n",
      "Epoch 14/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3356 - accuracy: 0.8477 - val_loss: 0.3327 - val_accuracy: 0.8418\n",
      "Epoch 15/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3315 - accuracy: 0.8468 - val_loss: 0.3318 - val_accuracy: 0.8425\n",
      "Epoch 16/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3349 - accuracy: 0.8430 - val_loss: 0.3322 - val_accuracy: 0.8425\n",
      "Epoch 17/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3353 - accuracy: 0.8451 - val_loss: 0.3393 - val_accuracy: 0.8376\n",
      "Epoch 18/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3394 - accuracy: 0.8462 - val_loss: 0.3404 - val_accuracy: 0.8370\n",
      "Epoch 19/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3369 - accuracy: 0.8408 - val_loss: 0.3391 - val_accuracy: 0.8394\n",
      "Epoch 20/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3373 - accuracy: 0.8428 - val_loss: 0.3378 - val_accuracy: 0.8388\n",
      "Epoch 21/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3354 - accuracy: 0.8445 - val_loss: 0.3370 - val_accuracy: 0.8406\n",
      "Epoch 22/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3325 - accuracy: 0.8413 - val_loss: 0.3358 - val_accuracy: 0.8449\n",
      "Epoch 23/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3352 - accuracy: 0.8446 - val_loss: 0.3345 - val_accuracy: 0.8400\n",
      "Epoch 24/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3337 - accuracy: 0.8440 - val_loss: 0.3335 - val_accuracy: 0.8394\n",
      "Epoch 25/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3332 - accuracy: 0.8457 - val_loss: 0.3325 - val_accuracy: 0.8394\n",
      "Epoch 26/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3295 - accuracy: 0.8475 - val_loss: 0.3319 - val_accuracy: 0.8388\n",
      "Epoch 27/100\n",
      "6572/6572 [==============================] - 0s 10us/sample - loss: 0.3307 - accuracy: 0.8506 - val_loss: 0.3315 - val_accuracy: 0.8388\n",
      "Epoch 28/100\n",
      "6572/6572 [==============================] - 0s 9us/sample - loss: 0.3331 - accuracy: 0.8456 - val_loss: 0.3314 - val_accuracy: 0.8400\n",
      "Epoch 29/100\n",
      "6572/6572 [==============================] - 0s 8us/sample - loss: 0.3315 - accuracy: 0.8440 - val_loss: 0.3318 - val_accuracy: 0.8394\n",
      "Epoch 30/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3311 - accuracy: 0.8472 - val_loss: 0.3316 - val_accuracy: 0.8394\n",
      "Epoch 31/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3331 - accuracy: 0.8457 - val_loss: 0.3311 - val_accuracy: 0.8394\n",
      "Epoch 32/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3335 - accuracy: 0.8466 - val_loss: 0.3310 - val_accuracy: 0.8400\n",
      "Epoch 33/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3309 - accuracy: 0.8478 - val_loss: 0.3306 - val_accuracy: 0.8418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3294 - accuracy: 0.8484 - val_loss: 0.3299 - val_accuracy: 0.8412\n",
      "Epoch 35/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3316 - accuracy: 0.8472 - val_loss: 0.3306 - val_accuracy: 0.8485\n",
      "Epoch 36/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3354 - accuracy: 0.8427 - val_loss: 0.3298 - val_accuracy: 0.8491\n",
      "Epoch 37/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3264 - accuracy: 0.8469 - val_loss: 0.3293 - val_accuracy: 0.8467\n",
      "Epoch 38/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3305 - accuracy: 0.8459 - val_loss: 0.3297 - val_accuracy: 0.8425\n",
      "Epoch 39/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3307 - accuracy: 0.8474 - val_loss: 0.3291 - val_accuracy: 0.8425\n",
      "Epoch 40/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3295 - accuracy: 0.8495 - val_loss: 0.3280 - val_accuracy: 0.8491\n",
      "Epoch 41/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3310 - accuracy: 0.8478 - val_loss: 0.3279 - val_accuracy: 0.8479\n",
      "Epoch 42/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3300 - accuracy: 0.8477 - val_loss: 0.3274 - val_accuracy: 0.8528\n",
      "Epoch 43/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3332 - accuracy: 0.8430 - val_loss: 0.3279 - val_accuracy: 0.8510\n",
      "Epoch 44/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3299 - accuracy: 0.8453 - val_loss: 0.3275 - val_accuracy: 0.8528\n",
      "Epoch 45/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3305 - accuracy: 0.8469 - val_loss: 0.3273 - val_accuracy: 0.8534\n",
      "Epoch 46/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3308 - accuracy: 0.8483 - val_loss: 0.3275 - val_accuracy: 0.8498\n",
      "Epoch 47/100\n",
      "6572/6572 [==============================] - 0s 7us/sample - loss: 0.3303 - accuracy: 0.8480 - val_loss: 0.3314 - val_accuracy: 0.8400\n",
      "Epoch 48/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3355 - accuracy: 0.8425 - val_loss: 0.3324 - val_accuracy: 0.8431\n",
      "Epoch 49/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3313 - accuracy: 0.8453 - val_loss: 0.3326 - val_accuracy: 0.8443\n",
      "Epoch 50/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3313 - accuracy: 0.8440 - val_loss: 0.3324 - val_accuracy: 0.8431\n",
      "Epoch 51/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3275 - accuracy: 0.8506 - val_loss: 0.3315 - val_accuracy: 0.8479\n",
      "Epoch 52/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3316 - accuracy: 0.8437 - val_loss: 0.3311 - val_accuracy: 0.8479\n",
      "Epoch 53/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3331 - accuracy: 0.8454 - val_loss: 0.3319 - val_accuracy: 0.8479\n",
      "Epoch 54/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3311 - accuracy: 0.8475 - val_loss: 0.3323 - val_accuracy: 0.8467\n",
      "Epoch 55/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3336 - accuracy: 0.8457 - val_loss: 0.3320 - val_accuracy: 0.8473\n",
      "Epoch 56/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3307 - accuracy: 0.8484 - val_loss: 0.3312 - val_accuracy: 0.8467\n",
      "Epoch 57/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3308 - accuracy: 0.8465 - val_loss: 0.3307 - val_accuracy: 0.8473\n",
      "Epoch 58/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3288 - accuracy: 0.8471 - val_loss: 0.3306 - val_accuracy: 0.8491\n",
      "Epoch 59/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3338 - accuracy: 0.8468 - val_loss: 0.3331 - val_accuracy: 0.8467\n",
      "Epoch 60/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3327 - accuracy: 0.8448 - val_loss: 0.3369 - val_accuracy: 0.8443\n",
      "Epoch 61/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3371 - accuracy: 0.8437 - val_loss: 0.3375 - val_accuracy: 0.8455\n",
      "Epoch 62/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3329 - accuracy: 0.8454 - val_loss: 0.3345 - val_accuracy: 0.8449\n",
      "Epoch 63/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3314 - accuracy: 0.8463 - val_loss: 0.3321 - val_accuracy: 0.8467\n",
      "Epoch 64/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3307 - accuracy: 0.8460 - val_loss: 0.3314 - val_accuracy: 0.8425\n",
      "Epoch 65/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3328 - accuracy: 0.8439 - val_loss: 0.3315 - val_accuracy: 0.8400\n",
      "Epoch 66/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3256 - accuracy: 0.8519 - val_loss: 0.3310 - val_accuracy: 0.8400\n",
      "Epoch 67/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3325 - accuracy: 0.8492 - val_loss: 0.3302 - val_accuracy: 0.8425\n",
      "Epoch 68/100\n",
      "6572/6572 [==============================] - 0s 5us/sample - loss: 0.3287 - accuracy: 0.8509 - val_loss: 0.3293 - val_accuracy: 0.8443\n",
      "Epoch 69/100\n",
      "6572/6572 [==============================] - 0s 6us/sample - loss: 0.3285 - accuracy: 0.8469 - val_loss: 0.3291 - val_accuracy: 0.8461\n",
      "Epoch 70/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3318 - accuracy: 0.8465 - val_loss: 0.3305 - val_accuracy: 0.8455\n",
      "Epoch 71/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3308 - accuracy: 0.8433 - val_loss: 0.3317 - val_accuracy: 0.8467\n",
      "Epoch 72/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3292 - accuracy: 0.8501 - val_loss: 0.3313 - val_accuracy: 0.8455\n",
      "Epoch 73/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3326 - accuracy: 0.8419 - val_loss: 0.3311 - val_accuracy: 0.8473\n",
      "Epoch 74/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3305 - accuracy: 0.8474 - val_loss: 0.3323 - val_accuracy: 0.8504\n",
      "Epoch 75/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3303 - accuracy: 0.8468 - val_loss: 0.3330 - val_accuracy: 0.8504\n",
      "Epoch 76/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3277 - accuracy: 0.8480 - val_loss: 0.3335 - val_accuracy: 0.8498\n",
      "Epoch 77/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3306 - accuracy: 0.8457 - val_loss: 0.3313 - val_accuracy: 0.8473\n",
      "Epoch 78/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3288 - accuracy: 0.8483 - val_loss: 0.3304 - val_accuracy: 0.8461\n",
      "Epoch 79/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3295 - accuracy: 0.8460 - val_loss: 0.3307 - val_accuracy: 0.8479\n",
      "Epoch 80/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3292 - accuracy: 0.8459 - val_loss: 0.3303 - val_accuracy: 0.8498\n",
      "Epoch 81/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3306 - accuracy: 0.8475 - val_loss: 0.3291 - val_accuracy: 0.8498\n",
      "Epoch 82/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3262 - accuracy: 0.8486 - val_loss: 0.3283 - val_accuracy: 0.8479\n",
      "Epoch 83/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3304 - accuracy: 0.8457 - val_loss: 0.3281 - val_accuracy: 0.8485\n",
      "Epoch 84/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3260 - accuracy: 0.8488 - val_loss: 0.3284 - val_accuracy: 0.8491\n",
      "Epoch 85/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3282 - accuracy: 0.8457 - val_loss: 0.3283 - val_accuracy: 0.8498\n",
      "Epoch 86/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3282 - accuracy: 0.8468 - val_loss: 0.3273 - val_accuracy: 0.8516\n",
      "Epoch 87/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3318 - accuracy: 0.8471 - val_loss: 0.3272 - val_accuracy: 0.8498\n",
      "Epoch 88/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3280 - accuracy: 0.8469 - val_loss: 0.3303 - val_accuracy: 0.8418\n",
      "Epoch 89/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3292 - accuracy: 0.8474 - val_loss: 0.3310 - val_accuracy: 0.8425\n",
      "Epoch 90/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3292 - accuracy: 0.8439 - val_loss: 0.3318 - val_accuracy: 0.8461\n",
      "Epoch 91/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3316 - accuracy: 0.8442 - val_loss: 0.3308 - val_accuracy: 0.8431\n",
      "Epoch 92/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3256 - accuracy: 0.8495 - val_loss: 0.3305 - val_accuracy: 0.8394\n",
      "Epoch 93/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3289 - accuracy: 0.8498 - val_loss: 0.3315 - val_accuracy: 0.8431\n",
      "Epoch 94/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3310 - accuracy: 0.8440 - val_loss: 0.3312 - val_accuracy: 0.8418\n",
      "Epoch 95/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3297 - accuracy: 0.8478 - val_loss: 0.3297 - val_accuracy: 0.8431\n",
      "Epoch 96/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3253 - accuracy: 0.8503 - val_loss: 0.3293 - val_accuracy: 0.8431\n",
      "Epoch 97/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3288 - accuracy: 0.8497 - val_loss: 0.3307 - val_accuracy: 0.8425\n",
      "Epoch 98/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3297 - accuracy: 0.8512 - val_loss: 0.3307 - val_accuracy: 0.8425\n",
      "Epoch 99/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3288 - accuracy: 0.8480 - val_loss: 0.3307 - val_accuracy: 0.8418\n",
      "Epoch 100/100\n",
      "6572/6572 [==============================] - 0s 4us/sample - loss: 0.3290 - accuracy: 0.8497 - val_loss: 0.3300 - val_accuracy: 0.8431\n"
     ]
    }
   ],
   "source": [
    "nEpochs = 100\n",
    "\n",
    "lossTrain = []\n",
    "lossTest = []\n",
    "accTrain = []\n",
    "accTest = []\n",
    "\n",
    "for iterTrain in np.arange(nShuffleRun):\n",
    "    \n",
    "    sigTrainSampleRange = np.arange(sigTrain.shape[0])\n",
    "    sigTrainSampleIndex = np.random.choice(sigTrainSampleRange, trainingSampleSize, replace=False)\n",
    "    sigTrainChosen = sigTrain[sigTrainSampleIndex,:]\n",
    "    bkgTrainSampleRange = np.arange(bkgTrain.shape[0])\n",
    "    bkgTrainSampleIndex = np.random.choice(bkgTrainSampleRange, trainingSampleSize, replace=False)\n",
    "    bkgTrainChosen = bkgTrain[bkgTrainSampleIndex,:]\n",
    "    \n",
    "    sigTestSampleRange = np.arange(sigTest.shape[0])\n",
    "    sigTestSampleIndex = np.random.choice(sigTestSampleRange, testSampleSize, replace=False)\n",
    "    sigTestChosen = sigTest[sigTestSampleIndex,:]\n",
    "    bkgTestSampleRange = np.arange(bkgTest.shape[0])\n",
    "    bkgTestSampleIndex = np.random.choice(bkgTestSampleRange, testSampleSize, replace=False)\n",
    "    bkgTestChosen = bkgTest[bkgTestSampleIndex,:]\n",
    "    \n",
    "    #print(sigTrainChosen.shape)\n",
    "    #print(bkgTrainChosen.shape)\n",
    "    \n",
    "    # Concatenate the signal and background with proper labels\n",
    "    x = np.concatenate((sigTrainChosen,bkgTrainChosen))\n",
    "    y = np.matrix([[1,0]]*sigTrainChosen.shape[0]+[[0,1]]*bkgTrainChosen.shape[0])\n",
    "    x_test = np.concatenate((sigTestChosen,bkgTestChosen))\n",
    "    y_test = np.matrix([[1,0]]*sigTestChosen.shape[0]+[[0,1]]*bkgTestChosen.shape[0])\n",
    "    print(\"Feature Space: \",x.shape)\n",
    "    \n",
    "    # Randomize the training samples\n",
    "    arr = np.arange(x.shape[0])\n",
    "    np.random.shuffle(arr)\n",
    "    x = x[arr,:]\n",
    "    y = y[arr,:]\n",
    "    \n",
    "    # Scale the input features\n",
    "    x = scaler.transform(x)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    \n",
    "    history = per.fit(x, \n",
    "                      y, \n",
    "                      validation_data=(x_test, y_test), \n",
    "                      epochs=nEpochs, \n",
    "                      batch_size=int(0.1*x.shape[0]))\n",
    "    \n",
    "    lossTrain.extend(history.history['loss'])\n",
    "    lossTest.extend(history.history['val_loss'])\n",
    "    accTrain.extend(history.history['accuracy'])\n",
    "    accTest.extend(history.history['val_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training Curve\n",
    "plt.clf()\n",
    "plt.plot(lossTrain, label='training')\n",
    "plt.plot(lossTest, label='test')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"loss.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "plt.plot(accTrain, label='training')\n",
    "plt.plot(accTest, label='test')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(\"accuracy.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
